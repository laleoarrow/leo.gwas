#' Convert CHR:BP to rsID (not recommended)
#'
#' This function takes a dataframe that must include columns 'CHR' and 'BP',
#' and it appends the corresponding rsID by querying the SNPlocs.Hsapiens.dbSNP155.GRCh37 database.
#' The function returns a dataframe with the rsIDs included.
#'
#' @param ref str indicating ref version.
#' - "GRCh37" for GRCh37 Ref panel
#' @param dat
#' - "GRCh38" for GRCh38 Ref panel
#' @return A dataframe with an additional 'RefSNP_id' column which contains the rsIDs.
#' @importFrom data.table ":="
#' @examples
#' pacman::p_load(data.table, BSgenome, leo.gwas)
#' library("SNPlocs.Hsapiens.dbSNP155.GRCh37") # for GRCh37
#' library("SNPlocs.Hsapiens.dbSNP155.GRCh38") # for GRCh38
#' df <- data.frame(
#'   CHR = c(1, 1),
#'   BP = c(15211, 15820)
#' )
#' result <- add_rsid(df); result
#' @export
add_rsid <- function(dat, ref = "GRCh37") {
  if (!("CHR" %in% colnames(dat)) || !("BP" %in% colnames(dat))) {
    stop("DataFrame must contain 'CHR' and 'BP' columns")
  }

  # Convert dat to data.table if it is not one already
  # library(data.table)
  if (!data.table::is.data.table(dat)) {data.table::setDT(dat)}
  dat[, ranges := paste0(CHR, ":", BP, "-", BP)]

  # Load SNP data - assuming GRCh37, modify if using GRCh38
  if (ref == "GRCh37") {
    snps <- SNPlocs.Hsapiens.dbSNP155.GRCh37::SNPlocs.Hsapiens.dbSNP155.GRCh37
  } else {
    snps <- SNPlocs.Hsapiens.dbSNP155.GRCh38::SNPlocs.Hsapiens.dbSNP155.GRCh38
  }

  # Find overlaps
  message(paste0("Translating RSID using: \n - BSgenome::snpsByOverlaps() \n - With ", snps@data_pkgname))
  snp.res <- BSgenome::snpsByOverlaps(snps, GRanges(dat$ranges))

  # Convert results to data.table
  snp.res.dt <- as.data.table(snp.res)
  snp.res.dt[, ranges := stringr::str_c(seqnames, ":", pos, "-", pos)]

  # Merge data
  trans.dat <- merge(snp.res.dt, dat, by = "ranges")
  columns_to_remove <- c("strand", "alleles_as_ambig", "ranges", "seqnames", "pos")
  trans.dat[, (columns_to_remove) := NULL]; gc()

  # Drop NA rsid and return
  # trans.dat <- trans.dat %>% drop_na(RefSNP_id)
  leo.gwas::leo_message("Remember to check if there is any NA in the RefSNP_id column.")
  leo.gwas::leo_message(">>> table(is.na(dat$RefSNP_id))")
  leo.gwas::leo_message(">>> vkh_meta %>% map_dbl(~sum(is.na(.)))")

  return(trans.dat)
}

#' Add rsID based on local reference file (recommended)
#'
#' This function takes a data frame with at least chromosome, position, and allele columns,
#' and matches rsID based on a local reference file, considering reversed/complement alleles.
#' It allows for flexibility in the names of the allele columns (e.g., 'REF'/'ALT' or 'A1'/'A2').
#' The function returns the original data frame with rsID added in the first column.
#'
#' @param dat A data frame containing at least chromosome, position, and allele columns.
#' @param local_ref A data frame containing at least 'ID' and 'SNP' columns.
#' @param chr_col Name of the chromosome column in 'dat'. Default is 'CHR'.
#' @param pos_col Name of the position column in 'dat'. Default is 'BP'.
#' @param a1_col Name of the first allele column in 'dat'.  Default is 'A1' (e.g., 'A1' or 'ALT').
#' @param a2_col Name of the second allele column in 'dat'.  Default is 'A2' (e.g., 'A2' or 'REF').
#' @return The original data frame with an added 'rsID' column as the first column.
#' @examples
#' \dontrun{
#' library(dplyr)
#' # Example data with REF and ALT
#' dat <- data.frame(
#'   CHR = c(7, 12, 4),
#'   BP = c(6013153, 126890980, 40088896),
#'   REF = c("G", "A", "T"),
#'   ALT = c("A", "G", "A")
#' )
#' # Reference data
#' local_ref <- data.frame(
#'   ID = c("7:6013153:A:G", "12:126890980:G:A", "4:40088896:A:T"),
#'   SNP = c("rs10000", "rs1000000", "rs10000000")
#' )
#' result <- add_rsid_using_ref(dat, local_ref, a1_col = "ALT", a2_col = "REF")
#' print(result)
#'
#' # Example data with A1 and A2
#' dat2 <- data.frame(
#'   CHR = c(7, 12, 4),
#'   POS = c(6013153, 126890980, 40088896),
#'   A1 = c("A", "G", "A"),
#'   A2 = c("G", "A", "T")
#' )
#' result2 <- add_rsid_using_ref(dat2, local_ref, pos_col = "POS")
#' print(result2)
#' }
#' @export
add_rsid_using_ref <- function(dat, local_ref, chr_col = "CHR", pos_col = "BP", a1_col = "A1", a2_col = "A2") {

  # Ensure required columns are present
  required_cols_dat <- c(chr_col, pos_col, a1_col, a2_col)
  required_cols_ref <- c("ID", "SNP")
  if (!all(required_cols_dat %in% colnames(dat))) {
    stop("Data frame 'dat' must contain columns: ", paste(required_cols_dat, collapse = ", "))
  }
  if (!all(required_cols_ref %in% colnames(local_ref))) {
    stop("Reference data 'local_ref' must contain columns: ", paste(required_cols_ref, collapse = ", "))
  }

  # Define function to get complement
  get_complement <- function(base) {
    dplyr::case_when(
      base == "A" ~ "T",
      base == "T" ~ "A",
      base == "C" ~ "G",
      base == "G" ~ "C",
      TRUE ~ base  # For non-standard bases, keep as is
    )
  }

  # Extract necessary columns as vectors
  CHR <- dat[[chr_col]]
  BP <- dat[[pos_col]]
  REF <- dat[[a1_col]]; REF_comp <- get_complement(REF)
  ALT <- dat[[a2_col]]; ALT_comp <- get_complement(ALT)
  # Construct indices
  index1 <- paste0(CHR, ":", BP, ":", REF, ":", ALT)       # Original
  index2 <- paste0(CHR, ":", BP, ":", ALT, ":", REF)       # Reversed
  index3 <- paste0(CHR, ":", BP, ":", REF_comp, ":", ALT_comp) # Complement
  index4 <- paste0(CHR, ":", BP, ":", ALT_comp, ":", REF_comp)  # Complement reversed

  # Match indices & Get rsID
  match_idx1 <- match(index1, local_ref$ID)
  match_idx2 <- match(index2, local_ref$ID)
  match_idx3 <- match(index3, local_ref$ID)
  match_idx4 <- match(index4, local_ref$ID)
  dat <- dat %>%
    dplyr::mutate(
      rsID = dplyr::case_when(
        !is.na(match_idx1) ~ local_ref$SNP[match_idx1],
        !is.na(match_idx2) ~ local_ref$SNP[match_idx2],
        !is.na(match_idx3) ~ local_ref$SNP[match_idx3],
        !is.na(match_idx4) ~ local_ref$SNP[match_idx4],
        TRUE ~ NA_character_
      )
    )

  # Remove auxiliary columns and reorder
  dat <- dat %>% dplyr::select(rsID, dplyr::everything())

  # Message about unmatched rsIDs
  na_count <- sum(is.na(dat$rsID))
  if (na_count > 0) {
    na_percent <- (na_count / nrow(dat)) * 100
    leo_message(paste0(na_count, " rsID(s) could not be matched and are set to NA. (", round(na_percent, 2), "%)"))
  }

  return(dat)
}


#' Convert rsID to CHR & BP
#'
#' This function takes a dataset with a column containing rsIDs (SNP IDs) and
#' adds the corresponding chromosome (CHR) and position (POS) information.
#' It queries the SNPlocs.Hsapiens.dbSNP155.GRCh37 database (or GRCh38 if specified) to retrieve the genomic positions.
#' The function returns a dataframe with the additional 'CHR' and 'POS' columns appended.
#'
#' @param dat A dataframe containing at least a column with SNP IDs (rsIDs).
#' @param snp_col A string indicating the column name containing SNP IDs (default is "SNP").
#' @param ref A string indicating the reference genome version. Default is "GRCh37", can also use "GRCh38".
#' @return A dataframe with additional 'CHR' and 'POS' columns.
#' @importFrom data.table ":="
#' @examples
#' pacman::p_load(data.table, dplyr, BSgenome, SNPlocs.Hsapiens.dbSNP155.GRCh37)
#' zuo_ref <- fread("/path/to/1KG-EAS-EAF.txt.gz") # Input dataset with rsID (SNP column)
#' result <- add_chrpos(zuo_ref, snp_col = "SNP", ref = "GRCh37")
#' @export
add_chrpos <- function(dat, snp_col = "SNP", ref = "GRCh37") {

  # Check if the SNP column exists in the dataframe
  if (!(snp_col %in% colnames(dat))) {
    stop(paste0("The column '", snp_col, "' is not found in the dataframe."))
  }

  # Load SNP reference data
  if (ref == "GRCh37") {
    snps <- SNPlocs.Hsapiens.dbSNP155.GRCh37::SNPlocs.Hsapiens.dbSNP155.GRCh37
    leo.gwas::leo_message("ℹ Loading SNPlocs.Hsapiens.dbSNP155.GRCh37 database.")
  } else if (ref == "GRCh38") {
    snps <- SNPlocs.Hsapiens.dbSNP155.GRCh38::SNPlocs.Hsapiens.dbSNP155.GRCh38
    leo.gwas::leo_message("ℹ Loading SNPlocs.Hsapiens.dbSNP155.GRCh38 database.")
  } else {
    stop("Invalid reference version. Please choose 'GRCh37' or 'GRCh38'.")
  }

  # Get CHR and POS for the SNPs from the SNPlocs database
  snp_info <- data.table::setDT(data.frame(snpsById(snps, dat[[snp_col]], ifnotfound = "drop"))) %>%
    dplyr::select(seqnames, pos, RefSNP_id) %>%
    dplyr::rename(CHR = seqnames, POS = pos, SNP = RefSNP_id) %>%
    unique()

  # Merge the SNP info with the original dataset, keeping all original columns
  merged_data <- merge(dat, snp_info, by.x = snp_col, by.y = "SNP", all.x = TRUE) %>%
    dplyr::select(dplyr::all_of(snp_col), CHR, POS, everything())

  # Check for missing SNPs (those not found in the SNP reference)
  missing_snps <- merged_data[is.na(merged_data$CHR), ]$SNP
  if (length(missing_snps) > 0) {
    message(paste0("Cannot find the following SNPs:\n", paste(missing_snps, collapse = ", "), "\n"))
  }

  # Return the final dataset with CHR and POS columns added
  return(merged_data)
}

#' Map Gene Symbols to Genomic Positions
#'
#' TODO: Merge all gene annotation function into one simple command.
#' This function maps gene symbols to their genomic positions (chromosome,
#' start, end, strand) using the specified method and genome assembly.
#'
#' The function supports two methods:
#' - `"bioconductor"`: uses Bioconductor packages. See [map_gene_to_chrbp_using_TxDb()].
#' - `"gtf"`: uses a GTF file. See [map_gene_to_chrbp_using_gtf()].
#'
#' @param genes A character vector of gene symbols or a data frame containing gene symbols.
#' @param gene_col The column name of gene symbols if `genes` is a data frame.
#' @param method The method to use: `"bioconductor"` or `"gtf"`.
#' @param genome The genome assembly to use: `"hg19"` or `"hg38"`.
#' @param ... Additional arguments to pass to the GTF method.
#'
#' @return A data frame with columns: gene_symbol, chr, bp_start, bp_end, strand.
#' @importFrom dplyr %>% select mutate left_join filter pull
#' @importFrom rlang sym
#' @examples
#' \dontrun{
#' # Using Bioconductor method with a character vector of gene symbols
#' leo_map_GtoCP(genes = c("TP53", "BRCA1", "EGFR"), method = "bioconductor", genome = "hg19")
#'
#' # Using Bioconductor method with a data frame
#' leo_map_GtoCP(genes = data.frame(gene_name = c("TP53", "BRCA1", "EGFR"), value = c(1.2, 3.4, 5.6)),
#'               gene_col = "gene_name", method = "bioconductor", genome = "hg19")
#'
#' # Using GTF method with a character vector of gene symbols
#' leo_map_GtoCP(genes = c("TP53", "BRCA1", "EGFR"), method = "gtf", genome = "hg38")
#'
#' # Using GTF method with a data frame
#' leo_map_GtoCP(genes = data.frame(gene_name = c("TP53", "BRCA1", "EGFR"), value = c(1.2, 3.4, 5.6)),
#'               gene_col = "gene_name", method = "gtf", genome = "hg38", download_dir = "~/project/ref/gtf")
#' }
#' @export
leo_map_GtoCP <- function(genes,
                          gene_col = NULL,
                          method = c("bioconductor", "gtf"),
                          genome = c("hg19", "hg38"),
                          ...) {
  method <- match.arg(method)
  genome <- match.arg(genome)

  if (method == "bioconductor") {
    result <- map_gene_to_chrbp_using_TxDb(genes = genes, gene_col = gene_col, genome = genome)
  } else if (method == "gtf") {
    result <- map_gene_to_chrbp_using_gtf(genes = genes, gene_col = gene_col, genome = genome, ...)
  } else {
    stop("Invalid method specified.")
  }

  return(result)
}


#' Map Gene Symbols Using Bioconductor Packages
#'
#' @param genes A character vector of gene symbols or a data frame containing gene symbols.
#' @param gene_col The column name of gene symbols if `genes` is a data frame.
#' @param genome The genome assembly to use: `"hg19"` or `"hg38"`.
#'  - For hg19, it needs `"TxDb.Hsapiens.UCSC.hg19.knownGene"` Bioconductor package
#'  - For hg38, it needs `"TxDb.Hsapiens.UCSC.hg38.knownGene"` Bioconductor package
#' @return A data frame with mapped results.
#' @importFrom dplyr %>% mutate left_join select pull
#' @importFrom rlang sym
#' @importFrom AnnotationDbi mapIds
#' @importFrom GenomicFeatures genes
#' @importFrom tidyr drop_na
#' @examples
#' \dontrun{
#' gene_symbols <- c("TP53", "BRCA1", "EGFR") # Example with gene symbol vector
#' map_gene_to_chrbp_using_TxDb(genes = gene_symbols, genome = "hg19")
#'
#' gene_symbols_df <- data.frame(GeneName = gene_symbols, OtherInformation = c(1,2,3)) # Example with data frame input
#' map_gene_to_chrbp_using_TxDb(genes = gene_symbols_df, gene_col = "GeneName" , genome = "hg19")
#' }
#' @export
map_gene_to_chrbp_using_TxDb <- function(genes, gene_col = NULL, genome = c("hg19", "hg38")) {
  genome <- match.arg(genome)

  # Load the appropriate TxDb package based on genome assembly
  if (genome == "hg19") {
    if (!requireNamespace("TxDb.Hsapiens.UCSC.hg19.knownGene", quietly = TRUE)) {
      message("Package 'TxDb.Hsapiens.UCSC.hg19.knownGene' is required. You can install it using BiocManager::install('TxDb.Hsapiens.UCSC.hg19.knownGene').")
      stop("Package 'TxDb.Hsapiens.UCSC.hg19.knownGene' is required.")
    }
    txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene::TxDb.Hsapiens.UCSC.hg19.knownGene
  } else if (genome == "hg38") {
    if (!requireNamespace("TxDb.Hsapiens.UCSC.hg38.knownGene", quietly = TRUE)) {
      message("Package 'TxDb.Hsapiens.UCSC.hg38.knownGene' is required. You can install it using BiocManager::install('TxDb.Hsapiens.UCSC.hg38.knownGene').")
      stop("Package 'TxDb.Hsapiens.UCSC.hg38.knownGene' is required.")
    }
    txdb <- TxDb.Hsapiens.UCSC.hg38.knownGene::TxDb.Hsapiens.UCSC.hg38.knownGene
  }

  # Load gene annotation package
  if (!requireNamespace("org.Hs.eg.db", quietly = TRUE)) {
    message("Package 'org.Hs.eg.db' is required. You can install it using BiocManager::install('org.Hs.eg.db').")
    stop("Package 'org.Hs.eg.db' is required.")
  }

  # Process input genes
  if (is.data.frame(genes)) {
    if (is.null(gene_col) || !(gene_col %in% colnames(genes))) {
      stop("Please specify a valid 'gene_col' that exists in the data frame.")
    }
    gene_col_sym <- rlang::sym(gene_col)
    input_df <- genes %>% tidyr::drop_na(!!gene_col)
    gene_symbols <- input_df %>% dplyr::pull(!!gene_col_sym)
  } else if (is.vector(genes)) {
    input_df <- data.frame(gene_symbol = gene_symbols, stringsAsFactors = FALSE) %>%
      tidyr::drop_na(gene_symbol)
    gene_symbols <- input_df %>% pull(gene_symbol)
  } else {
    stop("Input 'genes' must be a vector or a data frame.")
  }
  unique_gene_symbols <- unique(gene_symbols) # Use unique gene symbols for mapping
  message(sprintf("Total input genes: %d; Unique genes: %d", length(gene_symbols), length(unique_gene_symbols)))

  # Map gene symbols to Entrez IDs
  entrez_ids <- suppressMessages(
    AnnotationDbi::mapIds(org.Hs.eg.db::org.Hs.eg.db,
                          keys = unique_gene_symbols,
                          column = "ENTREZID",
                          keytype = "SYMBOL",
                          multiVals = "first") )
  # in case there are NA


  # Merge & Mapping
  mapping_df <- data.frame(
    gene_symbol = unique_gene_symbols,
    entrez_id = entrez_ids,
    stringsAsFactors = FALSE
  ) %>% dplyr::filter(!is.na(entrez_id))
  mapping_df <- mapping_df %>% dplyr::filter(!is.na(entrez_id))

  # Retrieve genomic positions using Entrez IDs
  suppressMessages(
    gene_locations <- GenomicFeatures::genes(txdb, columns = c("gene_id"),
                                             single.strand.genes.only = TRUE)
  )
  gene_locations_df <- as.data.frame(gene_locations) %>%
    dplyr::mutate(gene_id = as.character(gene_id))

  result_df <- mapping_df %>%
    dplyr::left_join(gene_locations_df, by = c("entrez_id" = "gene_id")) %>%
    dplyr::select(gene_symbol, chr = seqnames, bp_start = start, bp_end = end, strand) %>%
    dplyr::mutate(chr = gsub("^chr", "", chr)) %>%
    dplyr::distinct()

  # Group by gene_symbol to get unique positions
  standard_chr <- c(as.character(1:22), "X", "Y", "MT")
  result_df <- result_df %>%
    dplyr::filter(chr %in% standard_chr, !is.na(bp_start), !is.na(bp_end))

  # Inform about genes that could not be mapped
  unmapped_genes <- setdiff(unique_gene_symbols, result_df$gene_symbol)
  if (length(unmapped_genes) > 0) {
    message(paste0("⬇ A total of ", length(unmapped_genes), " could not be mapped ⬇"))
    message("The following genes could not be mapped: ", paste(unmapped_genes, collapse = ", "))
  }

  # Now merge the mapping back to the original input data
  final_df <- input_df %>%
    dplyr::left_join(result_df, by = stats::setNames("gene_symbol", gene_col))

  return(final_df)
}

#' Map Gene Symbols Using GTF File
#'
#' @param genes A character vector of gene symbols or a data frame containing gene symbols.
#' @param gene_col The column name of gene symbols if `genes` is a data frame.
#' @param genome The genome assembly to use: `"hg19"` or `"hg38"`.
#' @param gtf_file The path to a GTF file. If `NULL`, the function will download the appropriate GTF file.
#' @param download_dir The path where you wanna store the downloaded gtf file
#'
#' @return A data frame with mapping results.
#' @importFrom dplyr %>% mutate left_join select filter pull
#' @importFrom rlang sym
#' @importFrom GenomicFeatures makeTxDbFromGFF genes
#' @importFrom rtracklayer import
#' @examples
#' \dontrun{
#' gene_symbols <- c("TP53", "BRCA1", "EGFR")
#' map_gene_to_chrbp_using_gtf(genes = gene_symbols, genome = "hg38")
#'
#' gene_symbols_df <- data.frame(GeneName = gene_symbols, OtherInformation = c(1,2,3))
#' map_gene_to_chrbp_using_gtf(genes = gene_symbols_df, gene_col = "GeneName" , genome = "hg19")
#' }
#' @export
map_gene_to_chrbp_using_gtf <- function(genes, gene_col = NULL, genome = c("hg19", "hg38"), gtf_file = NULL, download_dir = "~/project/ref/gtf") {
  genome <- match.arg(genome)

  # Process input genes
  if (is.data.frame(genes)) {
    if (is.null(gene_col) || !(gene_col %in% colnames(genes))) {
      stop("Please specify a valid 'gene_col' that exists in the data frame.")
    }
    gene_col_sym <- rlang::sym(gene_col)
    gene_symbols <- genes %>% dplyr::pull(!!gene_col_sym)
    input_df <- genes
  } else if (is.vector(genes)) {
    gene_symbols <- genes
    input_df <- data.frame(gene_symbol = gene_symbols, stringsAsFactors = FALSE)
  } else {
    stop("Input 'genes' must be a vector or a data frame.")
  }
  unique_gene_symbols <- unique(gene_symbols) # Use unique gene symbols for mapping
  message(sprintf("Total input genes: %d; Unique genes: %d", length(gene_symbols), length(unique_gene_symbols)))

  # Set default download directory
  if (is.null(download_dir)) { download_dir <- "~/project/ref/gtf" }
  if (!dir.exists(download_dir)) { dir.create(download_dir, recursive = TRUE) }
  message(paste0(">>> Setting the download_dir: ", download_dir, "\n"))

  # Download GTF file if not provided
  if (is.null(gtf_file)) {
    if (genome == "hg19") {
      # gtf_url <- "ftp://ftp.ensembl.org/pub/grch37/current/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.gtf.gz"
      gtf_url <- "https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh37_latest/refseq_identifiers/GRCh37_latest_genomic.gtf.gz"
      gtf_file <- file.path(download_dir, basename(gtf_url))
    } else if (genome == "hg38") {
      # gtf_url <- "ftp://ftp.ensembl.org/pub/release-108/gtf/homo_sapiens/Homo_sapiens.GRCh38.108.gtf.gz"
      gtf_url <- "https://ftp.ncbi.nlm.nih.gov/refseq/H_sapiens/annotation/GRCh38_latest/refseq_identifiers/GRCh38_latest_genomic.gtf.gz"
      gtf_file <- file.path(download_dir, basename(gtf_url))
    }
    if (!file.exists(gtf_file)) {
      message("Downloading GTF file...")
      utils::download.file(gtf_url, destfile = gtf_file)
    }
  }

  # Create TxDb object from GTF file
  message("Creating TxDb object from GTF file...")
  txdb <- suppressWarnings( GenomicFeatures::makeTxDbFromGFF(gtf_file, format = "gtf") )

  # Retrieve gene locations
  gene_locations <- GenomicFeatures::genes(txdb)
  gene_locations_df <- as.data.frame(gene_locations)

  # Import GTF file to get gene symbols
  message("Importing GTF file to get gene symbols...")
  gtf_data <- rtracklayer::import(gtf_file)

  # Determine available attribute columns
  available_cols <- names(S4Vectors::mcols(gtf_data))
  if ("gene_name" %in% available_cols) {
    gene_id_col <- "gene_id"
    gene_name_col <- "gene_name"
  } else if ("gene" %in% available_cols) {
    gene_id_col <- "gene_id"
    gene_name_col <- "gene"
  } else {
    stop("Neither 'gene_name' nor 'gene' columns are present in the GTF file.")
  }
  gene_symbols_map <- unique(S4Vectors::mcols(gtf_data)[, c(gene_id_col, gene_name_col)])
  colnames(gene_symbols_map) <- c("gene_id", "gene_name")
  gene_symbols_map <- as.data.frame(gene_symbols_map)

  # Merge gene locations with gene symbols
  gene_locations_df <- gene_locations_df %>% # gene_locations_df <- as.data.frame(gene_locations) # (debug)
    dplyr::left_join(gene_symbols_map, by = c("gene_id")) %>%
    dplyr::distinct() %>%
    dplyr::mutate(
      # Extract numeric chromosome numbers
      chr = dplyr::case_when(
        grepl("^NC_", seqnames) ~ sub("^NC_0{0,}0*([0-9]+)\\..*", "\\1", seqnames),
        TRUE ~ NA_character_
      ),
      # Replace numeric codes for X and Y chromosomes
      chr = dplyr::case_when(
        chr == "23" ~ "X",
        chr == "24" ~ "Y",
        chr == "12920" ~ "MT",
        TRUE ~ chr
      )
    )

  # Filter out non-standard chromosomes and NA positions
  standard_chr <- c(as.character(1:22), "X", "Y", "MT")
  gene_locations_df <- gene_locations_df %>%
    dplyr::filter(chr %in% standard_chr, !is.na(start), !is.na(end))

  # Filter for unique gene symbols and group
  result_df <- gene_locations_df %>%
    dplyr::filter(gene_name %in% unique_gene_symbols) %>%
    dplyr::group_by(gene_name) %>%
    dplyr::summarise(
      chr = chr[1],
      bp_start = min(start),
      bp_end = max(end),
      strand = strand[1]
    ) %>%
    dplyr::ungroup() %>%
    dplyr::rename(gene_symbol = gene_name)

  # Inform about genes that could not be mapped
  mapped_genes <- result_df$gene_symbol
  unmapped_genes <- setdiff(unique_gene_symbols, mapped_genes)
  if (length(unmapped_genes) > 0) {
    message(paste0("⬇ A total of ", length(unmapped_genes), " could not be mapped ⬇"))
    message("The following genes could not be mapped: ", paste(unmapped_genes, collapse = ", "))
  }

  # Merge back with original input data
  final_df <- input_df %>%
    dplyr::left_join(result_df, by = stats::setNames("gene_symbol", gene_col))

  return(final_df)
}


#' Map Gene Symbols to Genomic Positions Using biomaRt
#'
#' This function queries gene symbols for their genomic positions (chromosome, start, end, strand)
#' using Ensembl's biomaRt for the specified genome assembly ("hg19" or "hg38").
#'
#' If the input is a data frame, the function retains all existing columns and
#' adds new columns with the mapping results.
#'
#' @param genes A character vector of gene symbols to query, or a data frame containing gene symbols.
#' @param gene_col The column name of gene symbols if `genes` is a data frame.
#' @param genome The genome assembly to use: "hg19" or "hg38".
#'
#' @return A data frame with the original data and new columns: chr, bp_start, bp_end, strand, gene_symbol.
#' @importFrom biomaRt useMart getBM
#' @importFrom dplyr left_join mutate filter
#' @examples
#' \dontrun{
#' # Query location of TP53, BRCA1, and EGFR genes
#' gene_symbols <- c("TP53", "BRCA1", "EGFR")
#' map_gene_to_chrbp_using_biomart(genes = gene_symbols, genome = "hg19")
#'
#' # Using a data frame with gene symbols
#' gene_symbols_df <- data.frame(GeneName = gene_symbols, OtherInfo = c(1, 2, 3))
#' map_gene_to_chrbp_using_biomart(genes = gene_symbols_df, gene_col = "GeneName", genome = "hg19")
#' }
#' @export
map_gene_to_chrbp_using_biomart <- function(genes, gene_col = NULL, genome = c("hg19", "hg38")) {
  # Check and set genome argument
  genome <- match.arg(genome)
  if (!requireNamespace("biomaRt", quietly = TRUE)) {
    stop("Package 'biomaRt' is required. Install it using BiocManager::install('biomaRt').")
  }

  # Connect to Ensembl based on genome assembly
  ensembl <- if (genome == "hg19") {
    biomaRt::useMart(biomart = "ENSEMBL_MART_ENSEMBL",
                     dataset = "hsapiens_gene_ensembl",
                     host = "https://grch37.ensembl.org")
  } else {
    biomaRt::useMart(biomart = "ENSEMBL_MART_ENSEMBL",
                     dataset = "hsapiens_gene_ensembl",
                     host = "https://www.ensembl.org")
  }

  # Process input genes
  if (is.data.frame(genes)) {
    if (is.null(gene_col) || !(gene_col %in% colnames(genes))) {
      stop("Please specify a valid 'gene_col' that exists in the data frame.")
    }
    gene_symbols <- genes[[gene_col]]
    input_df <- genes
  } else if (is.character(genes)) {
    gene_symbols <- genes
    input_df <- data.frame(gene_symbol = gene_symbols, stringsAsFactors = FALSE)
    gene_col <- "gene_symbol"
  } else {
    stop("Input 'genes' must be a character vector or a data frame.")
  }

  # Message about the number of input genes
  total_genes <- length(gene_symbols)
  unique_genes <- length(unique(gene_symbols))
  message(sprintf("Total input genes: %d, Unique genes: %d", total_genes, unique_genes))

  # Query gene information by symbol
  unique_gene_symbols <- unique(gene_symbols)
  gene_info <- biomaRt::getBM(
    attributes = c("chromosome_name", "start_position", "end_position", "strand",
                   "hgnc_symbol"), # "transcription_start_site" is also a attributes, but it returns too many results.
    filters = "hgnc_symbol",
    values = unique_gene_symbols,
    mart = ensembl
  )
  # Rename and re-format
  colnames(gene_info) <- c("chr", "bp_start", "bp_end", "strand", "gene_symbol")
  gene_info$gene_symbol <- as.character(gene_info$gene_symbol)

  # Filter out non-standard chromosomes (only keep 1-22, X, Y, MT)
  # standard_chr <- c(as.character(1:22), "X", "Y", "MT")
  # gene_info <- gene_info %>% dplyr::filter(chr %in% standard_chr) %>% dplyr::filter(!is.na(chr))

  # Merge back with original input to ensure consistency
  result_df <- input_df %>%
    dplyr::left_join(gene_info, by = stats::setNames("gene_symbol", gene_col))

  # Convert strand information to "+" and "-"
  result_df <- result_df %>%
    dplyr::mutate(strand = ifelse(strand == 1, "+", "-"))

  return(result_df)
}

#' Map Ensembl Gene IDs to Genomic Positions using biomaRt
#'
#' This function uses biomaRt to retrieve genomic positions (chr, bp_start, bp_end,
#' and strand) from the Ensembl database based on Ensembl gene IDs.
#'
#' @param ensembl_ids A character vector of Ensembl gene IDs, or a data frame containing this information.
#' @param ensembl_col If `ensembl_ids` is a data frame, specify the column name containing the Ensembl gene IDs.
#' @param verbose Logical indicating whether to print the unmapped information.
#' @param genome The genome version to use: "hg19" or "hg38".
#'
#' @return A data frame containing genomic position information, including ensembl_gene_id, chr, bp_start, bp_end, strand.
#' @importFrom biomaRt useMart getBM
#' @importFrom dplyr %>% left_join select mutate filter
#' @examples
#' \dontrun{
#' # Query using Ensembl gene IDs
#' ensembl_ids <- c("ENSG00000141510", "ENSG00000012048", "ENSG00000146648")
#' map_ensg_to_chrbp_using_biomaRt(ensembl_ids = ensembl_ids, genome = "hg19")
#'
#' # Use a data frame as input
#' gene_df <- data.frame(ensembl_id = ensembl_ids, value = c(1.2, 3.4, 5.6))
#' map_ensg_to_chrbp_using_biomaRt(ensembl_ids = gene_df, ensembl_col = "ensembl_id", genome = "hg19")
#' }
#' @export
map_ensg_to_chrbp_using_biomaRt <- function(ensembl_ids, ensembl_col = NULL, genome = c("hg19", "hg38"), verbose = F) {
  # Load required package
  if (!requireNamespace("biomaRt", quietly = TRUE)) {
    stop("Package 'biomaRt' is required. Please install it using BiocManager::install('biomaRt').")
  }

  genome <- match.arg(genome)

  # Select the appropriate Ensembl database
  if (genome == "hg19") {
    ensembl <- biomaRt::useMart(
      biomart = "ENSEMBL_MART_ENSEMBL",
      dataset = "hsapiens_gene_ensembl",
      host = "https://grch37.ensembl.org"
    )
  } else if (genome == "hg38") {
    ensembl <- biomaRt::useMart(
      biomart = "ENSEMBL_MART_ENSEMBL",
      dataset = "hsapiens_gene_ensembl",
      host = "https://www.ensembl.org"
    )
  }

  # Process the input Ensembl IDs
  if (is.data.frame(ensembl_ids)) {
    if (is.null(ensembl_col) || !(ensembl_col %in% colnames(ensembl_ids))) {
      stop("Please specify a valid 'ensembl_col', which is a column in the data frame.")
    }
    ensg_ids <- ensembl_ids[[ensembl_col]]
    input_df <- ensembl_ids
  } else if (is.vector(ensembl_ids)) {
    ensg_ids <- ensembl_ids
    input_df <- data.frame(ensembl_gene_id = ensg_ids, stringsAsFactors = FALSE)
    ensembl_col <- "ensembl_gene_id"
  } else {
    stop("Input 'ensembl_ids' must be a character vector or a data frame containing Ensembl gene IDs.")
  }

  unique_ensg_ids <- unique(ensg_ids)
  message(sprintf("Total number of input Ensembl gene IDs: %d; Number of unique gene IDs: %d",
                  length(ensg_ids), length(unique_ensg_ids)))

  # Remove version numbers from Ensembl gene IDs
  ensg_ids_clean <- sub("\\..*", "", ensg_ids)
  input_df[[ensembl_col]] <- ensg_ids_clean
  unique_ensg_ids <- unique(ensg_ids_clean)

  # Define attributes to retrieve
  attributes <- c("ensembl_gene_id", "chromosome_name", "start_position", "end_position",
                  "strand")

  # Retrieve gene information from Ensembl
  gene_info <- biomaRt::getBM(
    attributes = attributes,
    filters = "ensembl_gene_id",
    values = unique_ensg_ids,
    mart = ensembl
  )

  # Process strand information
  gene_info <- gene_info %>% dplyr::mutate(strand = ifelse(strand == 1, "+", "-"))
  colnames(gene_info) <- c("ensembl_gene_id", "chr", "bp_start", "bp_end", "strand")

  # Merge back to the input data frame
  result_df <- input_df %>% dplyr::left_join(gene_info, by = stats::setNames("ensembl_gene_id", ensembl_col))

  # Filter out non-standard chromosomes (optional)
  # standard_chr <- c(1:22, "X", "Y", "MT")
  # result_df <- result_df %>% dplyr::filter(chr %in% standard_chr)

  # Report unmapped Ensembl IDs
  if (verbose) {
    unmapped_ensg <- result_df %>%
      dplyr::filter(is.na(chr) | is.na(bp_start) | is.na(bp_end) | is.na(strand)) %>%
      dplyr::pull(!!rlang::sym(ensembl_col))
    if (length(unmapped_ensg) > 0) {
      message("The following Ensembl gene IDs could not be mapped to genomic positions:")
      print(unmapped_ensg)
    }
  }

  return(result_df)
}

#' Map Ensembl Gene IDs to Gene Symbols using biomaRt
#'
#' This function uses biomaRt to retrieve gene symbols based on Ensembl gene IDs.
#'
#' @param ensembl_ids A character vector of Ensembl gene IDs, or a data frame containing this information.
#' @param ensembl_col If `ensembl_ids` is a data frame, specify the column name containing the Ensembl gene IDs.
#' @param type How to handle cases where one Ensembl ID maps to multiple gene symbols. Options are "combine" (default) to combine them with a separator or "first" to only use the first symbol.
#' @param sep The separator to deal with one ensg mapped to multiple gene. Default with "/".
#' @param verbose Logical indicating whether to print the unmapped information.
#' @param genome The genome version to use: "hg19" or "hg38".
#'
#' @return A data frame containing Ensembl gene IDs and corresponding gene symbols.
#' @importFrom biomaRt useMart getBM
#' @importFrom dplyr %>% left_join mutate filter group_by summarise
#' @examples
#' \dontrun{
#' # Query using Ensembl gene IDs
#' ensembl_ids <- c("ENSG00000141510", "ENSG00000012048", "ENSG00000146648")
#' map_ensg_to_gene_using_biomaRt(ensembl_ids = ensembl_ids, genome = "hg19")
#'
#' # Use a data frame as input
#' gene_df <- data.frame(ensembl_id = ensembl_ids, value = c(1.2, 3.4, 5.6))
#' map_ensg_to_gene_using_biomaRt(ensembl_ids = gene_df, ensembl_col = "ensembl_id", genome = "hg19")
#' }
#' @export
map_ensg_to_gene_using_biomaRt <- function(ensembl_ids, ensembl_col = NULL,
  type = c("combine", "first"), sep = "/", genome = c("hg19", "hg38"), verbose = F) {

  # Load required package
  if (!requireNamespace("biomaRt", quietly = TRUE)) {
    stop("Package 'biomaRt' is required. Please install it using BiocManager::install('biomaRt').")
  }

  genome <- match.arg(genome)
  type <- match.arg(type)

  # Select the appropriate Ensembl database
  if (genome == "hg19") {
    ensembl <- biomaRt::useMart(
      biomart = "ENSEMBL_MART_ENSEMBL",
      dataset = "hsapiens_gene_ensembl",
      host = "https://grch37.ensembl.org"
    )
  } else if (genome == "hg38") {
    ensembl <- biomaRt::useMart(
      biomart = "ENSEMBL_MART_ENSEMBL",
      dataset = "hsapiens_gene_ensembl",
      host = "https://www.ensembl.org"
    )
  }

  # Process the input Ensembl IDs
  if (is.data.frame(ensembl_ids)) {
    if (is.null(ensembl_col) || !(ensembl_col %in% colnames(ensembl_ids))) {
      stop("Please specify a valid 'ensembl_col', which is a column in the data frame.")
    }
    ensg_ids <- ensembl_ids[[ensembl_col]]
    input_df <- ensembl_ids
  } else if (is.vector(ensembl_ids)) {
    ensg_ids <- ensembl_ids
    input_df <- data.frame(ensembl_gene_id = ensg_ids, stringsAsFactors = FALSE)
    ensembl_col <- "ensembl_gene_id"
  } else {
    stop("Input 'ensembl_ids' must be a character vector or a data frame containing Ensembl gene IDs.")
  }

  unique_ensg_ids <- unique(ensg_ids)
  message(sprintf("Total number of input Ensembl gene IDs: %d; Number of unique gene IDs: %d",
                  length(ensg_ids), length(unique_ensg_ids)))

  # Remove version numbers from Ensembl gene IDs
  ensg_ids_clean <- sub("\\..*", "", ensg_ids)
  input_df[[ensembl_col]] <- ensg_ids_clean
  unique_ensg_ids <- unique(ensg_ids_clean)

  # Define attributes to retrieve
  attributes <- c("ensembl_gene_id", "hgnc_symbol")

  # Retrieve gene information from Ensembl
  gene_info <- biomaRt::getBM(
    attributes = attributes,
    filters = "ensembl_gene_id",
    values = unique_ensg_ids,
    mart = ensembl
  )

  # Process based on 'type' parameter
  if (type == "combine") {
    gene_info <- gene_info %>%
      dplyr::group_by(ensembl_gene_id) %>%
      dplyr::summarise(hgnc_symbol = paste(unique(hgnc_symbol), collapse = sep)) %>%
      dplyr::ungroup()
  } else if (type == "first") {
    gene_info <- gene_info %>%
      dplyr::group_by(ensembl_gene_id) %>%
      dplyr::summarise(hgnc_symbol = first(hgnc_symbol)) %>%
      dplyr::ungroup()
  }

  # Merge back to the input data frame
  result_df <- input_df %>% dplyr::left_join(gene_info, by = stats::setNames("ensembl_gene_id", ensembl_col))
  result_df <- result_df %>% mutate(hgnc_symbol = ifelse(hgnc_symbol=="", NA, hgnc_symbol))

  # Report unmapped Ensembl IDs
  if (verbose) {
    unmapped_ensg <- result_df %>%
      dplyr::filter(is.na(hgnc_symbol)) %>%
      dplyr::pull(!!rlang::sym(ensembl_col))
    if (length(unmapped_ensg) > 0) {
      message("The following Ensembl gene IDs could not be mapped to gene symbols:")
      print(unmapped_ensg)
    }
  }

  return(result_df)
}



#' Map Ensembl IDs to Gene Symbols using `org.Hs.eg.db`
#'
#' This function maps Ensembl IDs to their corresponding gene symbols using the `org.Hs.eg.db` package.
#'
#' @param ensembl_ids A character vector of Ensembl IDs or a data frame containing Ensembl IDs.
#' @param ensembl_col The column name of Ensembl IDs if `ensembl_ids` is a data frame.
#' @return A data frame with two columns: the input Ensembl IDs and the corresponding gene symbols.
#' @importFrom dplyr %>% left_join pull
#' @importFrom rlang sym
#' @importFrom AnnotationDbi mapIds
#' @examples
#' \dontrun{
#' ensembl_ids <- c("ENSG00000141510.1", "ENSG00000012048", "ENSG00000146648") # Example with Ensembl ID vector
#' map_ensg_to_gene_using_org.Hs.eg.db(ensembl_ids = ensembl_ids)
#'
#' ensembl_ids_df <- data.frame(EnsemblID = ensembl_ids, OtherInformation = c(1,2,3)) # Example with data frame input
#' map_ensg_to_gene_using_org.Hs.eg.db(ensembl_ids = ensembl_ids_df, ensembl_col = "EnsemblID")
#' }
#' @export
map_ensg_to_gene_using_org.Hs.eg.db <- function(ensembl_ids, ensembl_col = NULL) {
  # Load required package
  if (!requireNamespace("org.Hs.eg.db", quietly = TRUE)) {
    message("Package 'org.Hs.eg.db' is required. You can install it using BiocManager::install('org.Hs.eg.db').")
    stop("Package 'org.Hs.eg.db' is required.")
  }

  # Process input Ensembl IDs
  if (is.data.frame(ensembl_ids)) {
    if (is.null(ensembl_col) || !(ensembl_col %in% colnames(ensembl_ids))) {
      stop("Please specify a valid 'ensembl_col' that exists in the data frame.")
    }
    ensembl_col_sym <- rlang::sym(ensembl_col)
    ensembl_id_values <- ensembl_ids %>% dplyr::pull(!!ensembl_col_sym)
    input_df <- ensembl_ids
  } else if (is.vector(ensembl_ids)) {
    ensembl_id_values <- ensembl_ids
    input_df <- data.frame(ensembl_id = ensembl_id_values, stringsAsFactors = FALSE)
    ensembl_col <- "ensembl_id"
  } else {
    stop("Input 'ensembl_ids' must be a vector or a data frame.")
  }

  # Remove version numbers from Ensembl IDs
  ensembl_id_clean <- sub("\\..*", "", ensembl_id_values)
  input_df[[ensembl_col]] <- ensembl_id_clean

  unique_ensembl_ids <- unique(ensembl_id_clean)
  message(sprintf("Total input Ensembl IDs: %d; Unique Ensembl IDs: %d",
                  length(ensembl_id_clean), length(unique_ensembl_ids)))

  # Map Ensembl IDs to Gene Symbols
  gene_symbols <- suppressMessages(
    AnnotationDbi::mapIds(
      org.Hs.eg.db::org.Hs.eg.db,
      keys = unique_ensembl_ids,
      column = "SYMBOL",
      keytype = "ENSEMBL",
      multiVals = "first"
    )
  )

  # Create mapping data frame
  mapping_df <- data.frame(
    ensembl_id = unique_ensembl_ids,
    gene_symbol = gene_symbols[unique_ensembl_ids],
    stringsAsFactors = FALSE
  ) %>% dplyr::filter(!is.na(gene_symbol))

  # Merge back with input data
  final_df <- dplyr::left_join(input_df, mapping_df, by = stats::setNames("ensembl_id", ensembl_col))

  return(final_df)
}

#' Map Genes to Their TSS Positions
#'
#' This function maps gene symbols to their transcription start sites (TSS) positions
#' using hg19 or hg38 genome assembly.
#'
#' @param genes A character vector of gene symbols or a data frame containing gene symbols.
#' @param gene_col The column name of gene symbols if `genes` is a data frame.
#' @param genome The genome assembly to use: `"hg19"` or `"hg38"`.
#' @param gtf_file The path to a GTF file. If `NULL`, the function will download the appropriate GTF file.
#' @param download_dir The path where you want to store the downloaded gtf file.
#' @param ... Pass to map_gene_to_chrbp_using_gtf. See [map_gene_to_chrbp_using_gtf()]
#'
#' @return A data frame with gene symbols and their TSS positions
#' @importFrom dplyr %>% select mutate case_when
#' @examples
#' \dontrun{
#' genes <- c("TP53", "BRCA1", "EGFR")
#' map_gene_to_tss_using_gtf(genes = genes, genome = "hg38")
#'
#' genes_df <- data.frame(GeneName = genes, OtherInfo = c(1,2,3))
#' map_gene_to_tss_using_gtf(genes = genes_df, gene_col = "GeneName", genome = "hg19")
#' }
#' @export
map_gene_to_tss_using_gtf <- function(genes, gene_col = NULL, genome = c("hg19", "hg38"),
                                      gtf_file = NULL, download_dir = "~/project/ref/gtf", ...) {

  # Get full mapping results using existing function
  mapping_results <- map_gene_to_chrbp_using_gtf(
    genes = genes,
    gene_col = gene_col,
    genome = genome,
    gtf_file = gtf_file,
    download_dir = download_dir,
    ...
  )

  # Calculate TSS based on strand, handling NA cases
  final_df <- mapping_results %>%
    dplyr::mutate(
      tss = dplyr::case_when(
        is.na(strand) ~ NA_integer_,
        strand == "+" ~ bp_start,  # TSS is at start for forward strand
        strand == "-" ~ bp_end,    # TSS is at end for reverse strand
        TRUE ~ NA_integer_
      )
    ) %>%
    dplyr::select(-bp_start, -bp_end)  # Remove the original start/end positions

  # Report genes without strand information
  genes_no_strand <- final_df %>%
    dplyr::filter(!is.na(chr), is.na(strand)) %>%
    dplyr::pull(!!rlang::sym(ifelse(is.null(gene_col), "gene_symbol", gene_col)))

  if (length(genes_no_strand) > 0) {
    message("\n⚠️ The following genes were mapped but lack strand information (TSS could not be determined):")
    message(paste(genes_no_strand, collapse = ", "))
  }

  return(final_df)
}

#' Map Ensembl Gene IDs to TSS Using biomaRt
#'
#' This function maps Ensembl gene IDs to their transcription start sites (TSS).
#' (Note that this is inferred using the gene start and end information based on strand)
#' It uses biomaRt for the specified genome assembly ("hg19" or "hg38").
#'
#' @param ensembl_ids A character vector of Ensembl gene IDs, or a data frame containing this information.
#' @param ensembl_col If `ensembl_ids` is a data frame, specify the column name containing the Ensembl gene IDs.
#' @param genome The genome version to use: "hg19" or "hg38".
#' @param ... pass to `map_ensg_to_chrbp_using_biomaRt`. See [map_ensg_to_chrbp_using_biomaRt()]
#'
#' @return A data frame with Ensembl gene IDs and their TSS positions.
#' @importFrom dplyr %>% mutate case_when select
#' @examples
#' \dontrun{
#' ensembl_ids <- c("ENSG00000141510", "ENSG00000012048", "ENSG00000146648")
#' map_ensg_to_tss_using_biomaRt(ensembl_ids = ensembl_ids, genome = "hg19")
#'
#' ensembl_ids_df <- data.frame(EnsemblID = ensembl_ids, OtherInfo = c(1, 2, 3))
#' map_ensg_to_tss_using_biomaRt(ensembl_ids = ensembl_ids_df, ensembl_col = "EnsemblID", genome = "hg38")
#' }
#' @export
map_ensg_to_tss_using_biomaRt <- function(ensembl_ids, ensembl_col = NULL, genome = c("hg19", "hg38"), ...) {
  mapping_results <- map_ensg_to_chrbp_using_biomaRt(
    ensembl_ids = ensembl_ids,
    ensembl_col = ensembl_col,
    genome = genome,
    ...
  )

  # Calculate TSS based on strand
  final_df <- mapping_results %>%
    dplyr::mutate(
      tss = dplyr::case_when(
        strand == "+" ~ bp_start,
        strand == "-" ~ bp_end,
        TRUE ~ NA_integer_
      )
    ) %>%
    dplyr::select(-bp_start, -bp_end)  # Remove original start/end positions

  return(final_df)
}


# Gene to Ensembl ID Mapping Functions -----------------------------------------

#' Map Gene Symbols to Ensembl IDs
#'
#' This function provides robust gene symbol to Ensembl ID mapping through:
#' \enumerate{
#'   \item{Local \code{org.Hs.eg.db} annotations (default)}
#'   \item{Ensembl BioMart web service (requires internet)}
#' }
#'
#' @param genes Input containing gene symbols. Can be:
#'   - Character vector of gene symbols
#'   - Data frame containing gene symbol column
#' @param gene_col Column name containing gene symbols when \code{genes} is data frame
#' @param method Mapping methodology:
#'   - "org.Hs.eg.db": Local Bioconductor annotations (default)
#'   - "biomart": Ensembl BioMart service
#' @param genome Genome assembly version (BioMart only):
#'   - "hg19": GRCh37 (default)
#'   - "hg38": GRCh38
#' @param type Multi-mapping handling:
#'   - "first": Return first valid ID (default)
#'   - "combine": Concatenate multiple IDs
#' @param sep Separator for combined IDs (default: "/")
#' @param batch_size BioMart query batch size (default: 100)
#'
#' @return Data frame with original data + ensembl_id column
#'
#' @importFrom AnnotationDbi mapIds
#' @importFrom dplyr left_join group_by summarise slice rename bind_rows
#' @importFrom biomaRt useMart getBM
#' @importFrom stats setNames na.omit
#' @importFrom stringr str_to_upper str_remove_all
#' @export
#'
#' @examples
#' \dontrun{
#' # Local annotation method
#' genes <- c("TP53", "BRCA1", "VEGFA")
#' result_local <- map_gene_to_ensembl(genes)
#'
#' # BioMart with custom parameters
#' gene_df <- data.frame(
#'   my_symbol = c("TP53", "BRCA1", "NONEXISTENT"),
#'   values = rnorm(3)
#' )
#' result_biomart <- map_gene_to_ensembl(
#'   gene_df,
#'   gene_col = "my_symbol",
#'   method = "biomart",
#'   genome = "hg19",
#'   batch_size = 50
#' )
#' }
map_gene_to_ensembl <- function(genes,
                                gene_col = NULL,
                                method = c("org.Hs.eg.db", "biomart"),
                                genome = c("hg19", "hg38"),
                                type = c("first", "combine"),
                                sep = "/",
                                batch_size = 100) {

  # Parameter validation
  method <- match.arg(method)
  genome <- match.arg(genome)
  type <- match.arg(type)

  # Dispatch to implementation
  if (method == "org.Hs.eg.db") {
    map_gene_to_ensembl_org(genes, gene_col, type, sep)
  } else {
    map_gene_to_ensembl_biomart(
      genes,
      gene_col,
      genome,
      type,
      sep,
      batch_size
    )
  }
}

# Local Annotation Method -----------------------------------------------------
map_gene_to_ensembl_org <- function(genes,
                                    gene_col,
                                    type,
                                    sep) {

  # Validate package installation
  if (!requireNamespace("org.Hs.eg.db", quietly = TRUE)) {
    stop("Bioconductor package org.Hs.eg.db required.\n",
         "Install with: BiocManager::install('org.Hs.eg.db')")
  }

  # Process input
  processed <- process_gene_input(genes, gene_col)
  input_df <- processed$data
  gene_vec <- clean_symbols(processed$genes)
  unique_genes <- unique(gene_vec)

  # Perform mapping
  ensembl_map <- suppressMessages(
    AnnotationDbi::mapIds(
      org.Hs.eg.db::org.Hs.eg.db,
      keys = unique_genes,
      column = "ENSEMBL",
      keytype = "SYMBOL",
      multiVals = if(type == "combine") "list" else "first"
    )
  )

  # Process multi-mappings
  if (type == "combine") {
    ensembl_map <- vapply(
      ensembl_map,
      function(x) paste(stats::na.omit(x), collapse = sep),
      character(1)
    )
  }

  # Create mapping structure
  mapping_df <- data.frame(
    clean_symbol = names(ensembl_map),
    ensembl_id = unname(ensembl_map),
    stringsAsFactors = FALSE
  )

  # Merge results
  final_df <- input_df %>%
    dplyr::mutate(clean_symbol = clean_symbols(.data[[processed$col_name]])) %>%
    dplyr::left_join(mapping_df, by = "clean_symbol") %>%
    dplyr::select(-clean_symbol)

  report_mapping_stats(final_df$ensembl_id)
  final_df
}

# BioMart Method --------------------------------------------------------------
map_gene_to_ensembl_biomart <- function(genes,
                                        gene_col,
                                        genome,
                                        type,
                                        sep,
                                        batch_size) {

  # Validate package installation
  if (!requireNamespace("biomaRt", quietly = TRUE)) {
    stop("biomaRt package required.\n",
         "Install with: BiocManager::install('biomaRt')")
  }

  # Configure BioMart connection
  mart <- tryCatch({
    host <- if (genome == "hg19") {
      "https://grch37.ensembl.org"
    } else {
      "https://www.ensembl.org"
    }

    biomaRt::useMart(
      "ENSEMBL_MART_ENSEMBL",
      dataset = "hsapiens_gene_ensembl",
      host = host
    )
  }, error = function(e) {
    stop("BioMart connection failed:\n",
         "Error: ", e$message, "\n",
         "Possible solutions:\n",
         "1. Check internet connection\n",
         "2. Verify Ensembl server status\n",
         "3. Try smaller batch_size")
  })

  # Process input
  processed <- process_gene_input(genes, gene_col)
  input_df <- processed$data
  gene_vec <- clean_symbols(processed$genes)
  unique_genes <- unique(gene_vec)

  # Batch processing
  results <- list()
  for (i in seq(1, length(unique_genes), batch_size)) {
    batch <- unique_genes[i:min(i + batch_size - 1, length(unique_genes))]

    batch_res <- tryCatch({
      biomaRt::getBM(
        attributes = c("external_gene_name", "ensembl_gene_id"),
        filters = "external_gene_name",
        values = batch,
        mart = mart
      )
    }, error = function(e) {
      message("Batch ", i, "-", i + batch_size - 1, " failed: ", e$message)
      NULL
    })

    if (!is.null(batch_res) && nrow(batch_res) > 0) {
      results[[length(results) + 1]] <- batch_res
    }
  }

  # Process results
  if (length(results) == 0) {
    warning("No mappings found in BioMart query")
    return(input_df %>% dplyr::mutate(ensembl_id = NA_character_))
  }

  bm_res <- dplyr::bind_rows(results) %>%
    dplyr::rename(hgnc_symbol = external_gene_name)

  # Handle multi-mappings
  if (type == "first") {
    bm_res <- bm_res %>%
      dplyr::group_by(.data$hgnc_symbol) %>%
      dplyr::slice(1) %>%
      dplyr::ungroup()
  } else {
    bm_res <- bm_res %>%
      dplyr::group_by(.data$hgnc_symbol) %>%
      dplyr::summarise(
        ensembl_gene_id = paste(
          unique(.data$ensembl_gene_id),
          collapse = sep
        ),
        .groups = "drop"
      )
  }

  # Merge results
  final_df <- input_df %>%
    dplyr::mutate(
      query_symbol = clean_symbols(.data[[processed$col_name]])
    ) %>%
    dplyr::left_join(
      bm_res,
      by = c("query_symbol" = "hgnc_symbol")
    ) %>%
    dplyr::rename(ensembl_id = ensembl_gene_id) %>%
    dplyr::select(-query_symbol)

  report_mapping_stats(final_df$ensembl_id)
  final_df
}

# Helper Functions ------------------------------------------------------------

#' Process and clean gene symbols
#' @keywords internal
clean_symbols <- function(x) {
  x %>%
    stringr::str_to_upper() %>%
    stringr::str_remove_all("[^A-Z0-9]") %>%
    iconv(to = "UTF-8")
}

#' Process input data
#' @keywords internal
process_gene_input <- function(genes, gene_col) {
  if (is.data.frame(genes)) {
    if (!is.null(gene_col)) {
      if (!gene_col %in% colnames(genes)) {
        stop("Gene column '", gene_col, "' not found. Available columns: ",
             paste(colnames(genes), collapse = ", "))
      }
      gene_vec <- genes[[gene_col]]
      col_name <- gene_col
    } else {
      stop("Must specify gene_col when input is a data frame")
    }
    return(list(
      data = genes,
      genes = gene_vec,
      col_name = col_name
    ))
  }

  if (is.character(genes)) {
    df <- data.frame(gene_symbol = genes, stringsAsFactors = FALSE)
    return(list(
      data = df,
      genes = genes,
      col_name = "gene_symbol"
    ))
  }

  stop("Invalid input type. Supported types: data.frame or character vector")
}

#' Report mapping statistics
#' @keywords internal
report_mapping_stats <- function(ensembl_col) {
  total <- length(ensembl_col)
  na_count <- sum(is.na(ensembl_col))
  mapped <- total - na_count

  message(
    "Mapping results:\n",
    "  Total genes: ", total, "\n",
    "  Mapped: ", mapped, " (", round(100 * mapped / total, 1), "%)\n",
    "  Failed: ", na_count, " (", round(100 * na_count / total, 1), "%)"
  )
}


# CpG annotation --------------------------------------------------------------
#' Annotate CpG Sites with Gene Information
#'
#' This function annotates a vector of CpG site probe IDs by retrieving corresponding gene names
#' from the Illumina 450k annotation package. It returns a data frame with the original CpG sites
#' and their associated gene names.
#'
#' @param cpg_vector A character vector of CpG site probe IDs to be annotated.
#' @param annotation_package A character string specifying the Illumina annotation package to use.
#'   It can be one of the following:
#'   - "IlluminaHumanMethylation450kanno.ilmn12.hg19" (default)
#'   - "IlluminaHumanMethylationEPICanno.ilm10b4.hg19"
#' @return A data frame with two columns:
#'   - `CpG_Site`: The original CpG site probe IDs.
#'   - `Gene`: The associated gene names. `NA` if no gene annotation is found.
#' @importFrom minfi getAnnotation
#' @importFrom dplyr filter pull mutate select
#' @importFrom cli cli_alert_info cli_alert_success
#' @examples
#' \dontrun{
#' library(IlluminaHumanMethylation450kanno.ilmn12.hg19)
#' library(IlluminaHumanMethylationEPICanno.ilm10b4.hg19)
#' # Example CpG probe IDs
#' cpg_ids <- c("cg00000029", "cg00000108", "cg00000109")
#' # Annotate CpG sites
#' annotate_cpg_sites(cpg_ids, "IlluminaHumanMethylation450kanno.ilmn12.hg19")
#' }
#' @export
annotate_cpg_sites <- function(cpg_vector,
                               annotation_package = "IlluminaHumanMethylation450kanno.ilmn12.hg19") {
  cli::cli_alert_info("Loading annotation package '{annotation_package}'...")
  cli::cat_bullet("Please do pre-library the required package", bullet_col = "blue")
  # Check if annotation package is installed
  if (annotation_package == "IlluminaHumanMethylation450kanno.ilmn12.hg19") {
    library(IlluminaHumanMethylation450kanno.ilmn12.hg19)
  } else if (annotation_package == "IlluminaHumanMethylationEPICanno.ilm10b4.hg19") {
    library(IlluminaHumanMethylationEPICanno.ilm10b4.hg19)
  } else {
    stop("Invalid annotation package. Please use either 'IlluminaHumanMethylation450kanno.ilmn12.hg19' or 'IlluminaHumanMethylationEPICanno.ilm10b4.hg19'.")
  }
  annotation_data_full <- minfi::getAnnotation(get(annotation_package))
  # mapping
  cli::cli_alert_info("Filtering annotation data for provided CpG sites...")
  annotation_subset <- annotation_data_full[cpg_vector, , drop = FALSE]
  gene_names <- annotation_subset$UCSC_RefGene_Name
  cli::cli_alert_success("Annotation completed successfully.")
  result_df <- data.frame(
    CpG_Site = cpg_vector,
    Gene = gene_names,
    stringsAsFactors = FALSE
  )
  return(result_df)
}
#' Give Messages with my color
#'
#' @param ... The messages you wanna messgae, which will be pasted together
#' @param color Str. Preferred color. Default is yellow.
#'              Options are "31" (red), "32" (green), "34" (blue), "95" (light purple)...
#' @param return Logical. If TRUE, returns the formatted string. If FALSE (Default), prints directly.
#'
#' @export
#' @examples
#' leo_message("This is a red message", color = "31")
#' leo_message("This is a green message", "\nhaha", color = "32")
#' leo_message("This is a blue ", "message", color = "34")
#' leo_message("This is a light purple message", color = "95")
#' leo_message(" 🦁🦁🦁 Welcome to use the LEO package ! 🦁🦁🦁")
leo_message <- function(..., color = "31", return = FALSE) {
  message_content <- paste0(..., collapse = " ")
  formatted_message <- paste0("\033[", color, "m", message_content, "\033[0m")
  message(formatted_message)
}

#' Log Messages with Timestamps
#'
#' Logs messages with timestamps
#' The messages are styled using the `cli` package for enhanced readability.
#' This function can not deal with {} function in the `cli` package.
#'
#' @param ... The message string to log, which will be pasted together.
#' @param level The log level. Options are `"info"`, `"success"`, `"warning"`, and `"danger"`.
#' @param levels All levels that is now supported.
#'
#' @return No return value. Outputs a formatted log message with a timestamp.
#' @export
#'
#' @examples
#' n1 <- 10; n2 <- 20
#' leo_log("Processing the", n1, "and", n2, "files.")
#' leo_log("Task completed successfully!", level = "success")
#' leo_log("Potential issue detected.", level = "warning")
#' leo_log("Error occurred during processing!", level = "danger")
leo_log <- function(..., level = "info") {
  msg <- paste(..., collapse = " "); timestamp <- paste0("[", format(Sys.time(), '%H:%M'),  "]")
  timestamp_colored <- switch(level,
                              "info" = cli::col_cyan(timestamp),     # cyan
                              "success" = cli::col_green(timestamp), # green
                              "warning" = cli::col_yellow(timestamp),# yellow
                              "danger" = cli::col_red(timestamp))    # red
  formatted_message <- paste(timestamp_colored, msg)
  switch(level,
         "info"    = cli::cli_alert_info(formatted_message),
         "success" = cli::cli_alert_success(formatted_message),
         "warning" = cli::cli_alert_warning(formatted_message),
         "danger"  = cli::cli_alert_danger(formatted_message)
         )
}



#' Get Unique Identifier for Genetic Data
#'
#' Get ID using CHR, BP, A2 (REF/Non-effect), A1 (ALT/Effect)
#'
#' @param x A data.frame that must contain the columns CHR, BP, A2, and A1.
#' Each column represents:
#' - CHR: Chromosome (It can be any in c("chrom", "CHR", "Chromosome", "chromosome", "Chr"))
#' - BP/POS: Base pair position (It can be any in c("pos", "POS", "position", "BP", "Position", "Bp"))
#' - A2: Reference allele/non-effect allele (It can be any in c("A2", "Allele2", "allele2", "a2", "REF", "Ref", "ref", "Non-effect"))
#' - A1: Alternative allele/effect allele (It can be any in c("A1", "Allele1", "allele1", "a1", "ALT", "Alt", "alt", "Effect"))
#' @param count_A1_A2 If T, will count the number of characters in A1 and A2
#'
#' @return A data.frame with an additional 'ID' column (if count_A1_A2=T, containing unique identifiers and character counts of A1 and A2)
#' @import dplyr
#' @examples
#' df <- data.frame(chrom = c(1, 1, 2), pos = c(12345, 54321, 11111), A1 = c("A", "T", "G"), A2 = c("G", "C", "A"))
#' get_id(df); get_id(df, count_A1_A2 = T)
#' @export
get_id <- function(x, count_A1_A2 = F) {
  # require(dplyr)
  # possible colnames for CHR and POS
  chrom_cols <- c("chrom", "CHR", "Chromosome", "chromosome", "Chr")
  pos_cols <- c("pos", "POS", "position", "BP", "Position", "Bp")
  a1_cols <- c("A1", "Allele1", "allele1", "a1", "ALT", "Alt", "alt", "Effect")
  a2_cols <- c("A2", "Allele2", "allele2", "a2", "REF", "Ref", "ref", "Non-effect")

  chrom_col <- intersect(chrom_cols, names(x)); if(length(chrom_col) == 0){stop("No chromosome column found in the dataframe.")}
  chrom_col <- chrom_col[1]

  pos_col <- intersect(pos_cols, names(x)); if(length(pos_col) == 0){stop("No position column found in the dataframe.")}
  pos_col <- pos_col[1]

  a1_col <- intersect(a1_cols, names(x)); if(length(a1_col) == 0){stop("No A1 column found in the dataframe.")}
  a1_col <- a1_col[1]

  a2_col <- intersect(a2_cols, names(x)); if(length(a2_col) == 0){stop("No A2 column found in the dataframe.")}
  a2_col <- a2_col[1]

  if (count_A1_A2 == TRUE) {
    x <- x %>% dplyr::mutate(ID = paste(.data[[chrom_col]], .data[[pos_col]], .data[[a2_col]], .data[[a1_col]], sep = ":"),
                             A1_n = base::nchar(.data[[a1_col]]), A2_n = nchar(.data[[a2_col]]))
  } else {
    x <- x %>% dplyr::mutate(ID = paste(.data[[chrom_col]], .data[[pos_col]], .data[[a2_col]], .data[[a1_col]], sep = ":"))
  }

  return(x)
}

#' Give precise p-value for chi-square test
#'
#' Sometimes you get a p-value of 0 when you perform a chi-square test or other analysis.
#' This is because the p-value is so small that R rounds it to 0. This function gives you
#' a more precise p-value.
#'
#' @param chisq_value numeric, chi-square value
#' @param df numeric, degree of freedom
#' @param digits numeric, digits for output to illustrate
#' @param prec numeric, precision for mpfr() function
#'
#' @return A precise p-value in scientific format
#' @export
#'
#' @examples
#' # install.packages("Rmpfr")
#' library(Rmpfr)
#' chisq_value <- 2629; df <- 1
#' p_value <- chisq_p_value(chisq_value, df)
#' print(p_value)
chisq_p_value <- function(chisq_value, df, digits = 4, prec = 100) {
  log_p_value <- pchisq(chisq_value, df, lower.tail = FALSE, log.p = TRUE)
  p_value <- exp(mpfr(log_p_value, prec = prec))
  # p_value <- format(p_value, scientific = TRUE, digits = digits)
  return(p_value)
}

#' Exclude HLA region from genomic summary data
#'
#' This function filters out entries within the HLA region on a specified chromosome
#' and position range. The default HLA region is set to chromosome 6, between 25Mb and 34Mb.
#' Custom chromosome and position bounds can be specified.
#'
#' @param data A data frame containing genomic data.
#' @param chromosome_col The name of the column representing chromosome numbers (default is CHR).
#' @param position_col The name of the column representing genomic positions (default is BP).
#' @param lower_bound The lower boundary of the HLA region in base pairs (default is 25e6).
#' @param upper_bound The upper boundary of the HLA region in base pairs (default is 34e6).
#'
#' @return A data frame excluding rows that fall within the specified HLA region.
#' @importFrom dplyr filter
#' @export
#' @examples
#' example_data <- data.frame(
#'   SNP = c("rs1", "rs2", "rs3", "rs4"),
#'   CHR = c(6, 6, 6, 7),
#'   POS = c(26000000, 33000000, 35000000, 29000000)
#' )
#' result_data <- exclude_HLA(example_data, chromosome_col="CHR", position_col="POS")
#' print(result_data)
exclude_HLA <- function(data, chromosome_col="CHR", position_col="BP", lower_bound=25e6, upper_bound=34e6) {
  filtered_data <- data %>%
    dplyr::filter(!(!!sym(chromosome_col) == 6 &
                      !!sym(position_col) >= lower_bound &
                      !!sym(position_col) <= upper_bound))
  return(filtered_data)
}

#' Count or Identify Matches of a Pattern in a Vector
#'
#' This function counts the number of elements in a vector that contain a given pattern,
#' or returns a logical vector indicating which elements match the pattern.
#'
#' @param vector A character vector to be searched.
#' @param pattern The pattern to match (regular expression).
#' @param return A string specifying the return type: "count" for number of matches, or "logi" for a logical vector.
#'
#' @return An integer representing the number of matches if return is "count",
#'         or a logical vector indicating which elements match the pattern if return is "logi".
#' @export
#' @examples
#' vec <- c("abc", "def", "xyz", "abcd")
#' count_matching_elements(vec, "abc", return = "count")  # Returns 2
#' count_matching_elements(vec, "abc", return = "logi")   # Returns c(TRUE, FALSE, FALSE, TRUE)
count_matching_elements <- function(vector, pattern, return = "count") {
  # Ensure the input is a character vector
  if (!is.character(vector)) {
    stop("Input must be a character vector.")
  }

  # Create a logical vector for matching elements
  matches <- grepl(pattern, vector, ignore.case = TRUE)

  if (return == "count") {
    return(sum(matches))  # Return the count of matching elements
  } else if (return == "logi") {
    return(matches)  # Return the logical vector
  } else {
    stop("Invalid return value. Use 'count' or 'logi'.")
  }
}

#' Count or Identify Duplicates in a Vector
#'
#' This function counts the number of duplicate elements in a vector,
#' or returns a logical vector indicating which elements are duplicates.
#'
#' @param vector A vector to be checked for duplicates.
#' @param return A string specifying the return type: "count" for number of duplicates, or "logi" for a logical vector.
#'
#' @return An integer representing the number of duplicates if return is "count",
#'         or a logical vector indicating which elements are duplicates if return is "logi".
#' @export
#' @examples
#' vec <- c("a", "b", "c", "a", "b", "d")
#' count_duplicate_element(vec, return = "count")  # Returns 4
#' count_duplicate_element(vec, return = "logi")   # Returns c(TRUE, TRUE, FALSE, TRUE, TRUE, FALSE)
count_duplicate_element <- function(vector, return = "count") {
  # Find duplicates
  duplicate_indices <- duplicated(vector) | duplicated(vector, fromLast = TRUE)

  if (return == "count") {
    return(sum(duplicate_indices))  # Return the count of duplicates
  } else if (return == "logi") {
    return(duplicate_indices)  # Return the logical vector
  } else {
    stop("Invalid return value. Use 'count' or 'logi'.")
  }
}


#' Across a df to count na
#'
#' This function summarize NA values in each column of a data frame.
#'
#' @param df a data frame
#' @return a data frame with the number of NA values in each column
#' @export
#' @examples
#' df <- data.frame(a = c(1, 2, NA, 4), b = c(NA, 2, 3, 4))
#' summarize_na(df)
across_df_na <- function(df){
  df %>% dplyr::summarise(across(everything(), ~sum(is.na(.))))
}

#' Across a df to count TRUE and FALSE
#'
#' This function summarizes both TRUE and FALSE values in each column of a data frame.
#'
#' @param df a data frame
#' @param type "T" for TRUE counts (default), "F" for FALSE counts
#' @return a data frame with the number of TRUE or FALSE values in each column
#' @export
#' @examples
#' df <- data.frame(a = c(TRUE, FALSE, TRUE, TRUE), b = c(FALSE, TRUE, TRUE, TRUE))
#' across_df_TF(df) # Count TRUE (default)
#' across_df_TF(df, "F") # Count FALSE
across_df_TF <- function(df, type = "T"){
  type <- match.arg(type, c("T", "F"))
  if(type == "T"){
    df %>% dplyr::summarise(across(everything(), ~sum(.)))
  } else {
    df %>% dplyr::summarise(across(everything(), ~sum(!.)))
  }
}
##################################################
# This script is for functions for visualization #
# @author: Lu Ao (luao@stu.cqmu.edu.cn)          #
##################################################
#  ------------------------------ Basics Function ------------------------------
#' Apply Color Palette to ggplot
#'
#' This function applies a specified color palette to a ggplot object,
#' supporting `ggsci`, `RColorBrewer`, and `viridis` palettes, as well as custom colors.
#'
#' @param plot A ggplot object to which the color palette will be applied.
#' @param color_palette A character string specifying the color palette to use.
#'                      Options include `ggsci` palettes ("npg", "lancet", "jama", etc.),
#'                      `RColorBrewer` palettes, `viridis` palettes, or a custom vector of colors.
#'
#' @return A ggplot object with the applied color palette.
#' @importFrom ggsci scale_color_npg scale_color_lancet scale_color_jama scale_color_nejm scale_color_d3 scale_color_tron scale_color_igv scale_color_ucscgb scale_color_aaas scale_color_futurama scale_color_rickandmorty scale_color_simpsons
#' @importFrom RColorBrewer brewer.pal
#' @import ggplot2
leo_scale_color <- function(plot, color_palette = "npg") {
  # Check if color_palette is a recognized ggsci palette
  if (color_palette == "npg") {
    plot <- plot + ggsci::scale_color_npg()
  } else if (color_palette == "lancet") {
    plot <- plot + ggsci::scale_color_lancet()
  } else if (color_palette == "ucscgb") {
    plot <- plot + ggsci::scale_color_ucscgb()
  } else if (color_palette == "aaas") {
    plot <- plot + ggsci::scale_color_aaas()
  } else if (color_palette == "futurama") {
    plot <- plot + ggsci::scale_color_futurama()
  } else if (color_palette == "rickandmorty") {
    plot <- plot + ggsci::scale_color_rickandmorty()
  } else if (color_palette == "simpsons") {
    plot <- plot + ggsci::scale_color_simpsons()
  }
  # Check if color_palette is a recognized RColorBrewer palette
  else if (color_palette %in% rownames(RColorBrewer::brewer.pal.info)) {
    plot <- plot + scale_color_brewer(palette = color_palette)
  }
  # Use a custom color vector if provided
  else if (is.vector(color_palette) && all(is.character(color_palette))) {
    plot <- plot + scale_color_manual(values = color_palette)
  } else {
    warning("Color palette not recognized. Default ggplot2 colors will be used.")
  }
  return(plot)
}

#' Draw Correlation between Two Vectors
#'
#' This function creates a scatter plot to visualize the correlation between two vectors,
#' displaying the correlation coefficient and p-value on the plot.
#' It uses `ggplot2` for visualization and `ggsci` for color schemes.
#'
#' @importFrom ggplot2 ggplot aes geom_point geom_smooth labs annotate theme_minimal theme element_text element_blank
#'
#' @param vector_x A numeric vector.
#' @param vector_y A numeric vector of the same length as \code{vector_x}.
#' @param method A character string specifying the correlation method ("spearman" or "pearson").
#'               Defaults to "spearman".
#' @param color_palette A character string or vector specifying the color palette to use.
#'               Can be a palette name from `ggsci`, `RColorBrewer`, or a custom color vector.
#' @param title A character string for the plot title. Defaults to "Correlation Plot".
#' @param xlab A character string for the x-axis label. Defaults to "Vector X".
#' @param ylab A character string for the y-axis label. Defaults to "Vector Y".
#' @param point_size Numeric value for point size in the scatter plot. Defaults to 4.
#' @param point_color A character string specifying color for the scatter points. Defaults to "#BB7CD8".
#' @param alpha Numeric value for the transparency of points. Defaults to 0.75.
#' @param line_color A character string specifying color for the trend line. Defaults to "#BB7CD8".
#' @param line_type Character specifying the type of line ("solid", "dashed", etc.). Defaults to "dashed".
#' @param line_size Numeric value specifying the thickness of the trend line. Defaults to 1.2.
#' @param ci_alpha Numeric value for the transparency level of the confidence interval. Defaults to 0.6.
#' @param title_size Numeric value for title text size. Defaults to 14.
#' @param xlab_size Numeric value for x-axis label text size. Defaults to 12.
#' @param ylab_size Numeric value for y-axis label text size. Defaults to 12.
#' @param axis_text_size Numeric value for axis text size. Defaults to 10.
#' @param ... Additional arguments passed to \code{\link[stats]{cor.test}}.
#' @param point_stroke It could also be NA!!!
#'
#' @return A ggplot object representing the scatter plot with correlation information.
#' @export
#' @seealso \code{\link{correlation_calculate}} for calculating correlation coefficients and p-values.
#' @seealso [leo_scale_color()] for applying color palettes to ggplot objects.
#' @examples
#' vector_x <- c(10, 2, 3, 4, 5)
#' vector_y <- c(5, 6, 7, 8, 7)
#' correlation_draw(vector_x, vector_y, method = "pearson", point_size = 10, color_palette = "npg")
correlation_draw <- function(vector_x, vector_y, method = "spearman", color_palette = "npg",
                             title = "Correlation Plot", xlab = "Vector X", ylab = "Vector Y",
                             point_size = 1.5, point_color = "#BB7CD8", point_stroke = 1, alpha = 0.75,
                             line_color = "#BB7CD8", line_type = "dashed", line_size = 1.2,
                             ci_alpha = 0.2, title_size = 16, xlab_size = 14,
                             ylab_size = 14, axis_text_size = 14, ...) {

  # Calculate correlation
  correlation_result <- correlation_calculate(vector_x, vector_y, method = method, ...)
  correlation_coefficient <- round(correlation_result$correlation_coefficient, 3)
  p_value <- round(correlation_result$p_value, 3)

  # Create scatter plot with correlation coefficient and p-value annotation
  plot <- ggplot2::ggplot(data = data.frame(vector_x, vector_y), ggplot2::aes(x = vector_x, y = vector_y)) +
    ggplot2::geom_point(size = point_size, color = "black", fill = point_color, alpha = alpha, stroke = point_stroke, shape = 21) +
    ggplot2::geom_smooth(method = "lm", color = line_color, linetype = line_type,
                         size = line_size, se = TRUE, fill = line_color, alpha = ci_alpha) +  # Add confidence interval shading
    ggplot2::labs(title = title, x = xlab, y = ylab) +
    ggplot2::annotate(
      "text", x = Inf, y = Inf,
      label = paste("Correlation:", correlation_coefficient, "\nP-value:", p_value),
      hjust = 1.1, vjust = 1.2,
      size = 5, color = "black"
    ) +
    ggplot2::theme_classic() +
    ggplot2::theme(
      plot.title = ggplot2::element_text(size = title_size),
      axis.text = ggplot2::element_text(size = axis_text_size, color = "black"),
      axis.title.x = ggplot2::element_text(size = xlab_size, color = "black"),
      axis.title.y = ggplot2::element_text(size = ylab_size, color = "black"),
      axis.line = ggplot2::element_line(color = "black"),      # Set axis line color
      axis.ticks = ggplot2::element_line(color = "black"),     # Set axis ticks color
      panel.grid = ggplot2::element_blank()                    # Remove grid
    )

  # Apply color palette using the helper function
  # plot <- leo_scale_color(plot, color_palette)

  return(plot)
}

#  ------------------------------ Reginal Plot Function ------------------------------

#' Loci_plot: Calculate the LD-matrix (LD r2) for the index SNP
#' @param gwas gwas summary data that needs to select loci and calculate r2
#' @param index index snp
#' @param win window size to locally calculate the r2; set it larger than that you want to plot; # default calculate 1MB
#' @param pop only applicable under 500 snps; dont use it anyway
#' @param ld_calculation if calculate the LD locally, defaut T; use F if the index snp is a rare variant (MAF<0.01)
#' @param bfile bfile
#' @param plink_bin plinkbinr::get_plink_exe()
#'
#' @return loci data with calculated r2
#' @export
ld_ps_index <- function(gwas, index = "rs999", # ps for pre-select
                        win = 1000,
                        ld_calculation = T, bfile = "/Users/leoarrow/project/ref/1kg.v3/EAS", plink_bin = plinkbinr::get_plink_exe()){
  # extract the index SNP
  chr <- gwas %>% dplyr::filter(SNP == index) %>% pull(CHR); message(paste0("CHR for the index snp is "), chr)
  pos <- gwas %>% dplyr::filter(SNP == index) %>% pull(POS); message(paste0("POS for the index snp is "), pos)
  # extract the SNPs in the LD window
  loci <- gwas %>% dplyr::filter(CHR == chr, POS>=pos-win/2*1000, POS<=pos+win/2*1000) %>% tidyr::drop_na() %>% distinct(SNP, .keep_all = T)
  message(paste0("SNP number in the loci is "), nrow(loci))
  # calculate the LD matrix
  if (ld_calculation) {
    ld <- ieugwasr::ld_matrix(
      variants = unique(loci$SNP),
      with_alleles = F,
      # pop = pop,
      bfile = bfile,
      plink_bin = plink_bin
    )
    ld_df <- ld %>% as.data.frame()
    ld_df <- tibble::rownames_to_column(ld_df, var = "SNP")
    ld_df_index <- ld_df %>% dplyr::select(SNP, index) %>% set_names("SNP", "r") %>% mutate(r2 = r^2)
    # merge the LD matrix with the GWAS data
    loci <- loci %>% left_join(ld_df_index %>% dplyr::select(-r), by = "SNP") %>% as.data.frame()
  }
  return(loci)
}

#' Loci_plot: prepare the locus data for locuszoomr
#' @param loci_data output from ld_ps_index
#' @param gene gene loci
#' @param index_snp indexed snp
#' @param online_ld whether to use online LD; default is F
#' @param flank flank size for the locus plot
#' @return prepared data which could be pass to save_regional_plot
#' @export
locuszoomr_loc <- function(loci_data, gene, online_ld = F, index_snp, flank) {
  #   ----- loc_plot using `locuszoomr`
  loc <- locus(data = loci_data,
               gene = gene,
               index_snp = index_snp,
               chrom = "CHR", #  detect_cols(., chrom, pos, p, labs, yvar)
               pos = "POS",
               p = "P",
               labs = "SNP",
               flank = flank, # up/low flank setting; 1e5 = 100kb
               LD = "r2",
               ens_db = "EnsDb.Hsapiens.v75")


  #  ----- LD
  if (online_ld) {loc <- link_LD(loc, pop = "EUR", token = "8866c6877cb8", method = "matrix")}
  #  ----- recomb
  library(rtracklayer)
  local_recomb_19 <- "/Users/leoarrow/project/ref/recombMap/hapMapRelease24CombinedRecombMap.bw"
  recomb.hg19 <- import.bw(local_recomb_19)
  loc <- link_recomb(loc, recomb = recomb.hg19)
  return(loc)
}

#' Loci_plot: save_regional_plot
#'
#' @param path path to store the plot; make sure the path is exist
#' @param loc output from locuszoomr_loc
#' @param gene gene
#' @param width width
#' @param save if T, will save plot to path; if F, return the plot only
#' @param labels labels; in case you need to indicate the index SNP and other SNP
#' @param border border for gene track
#' @param height height
#'
#' @export
save_regional_plot <- function(path, loc, gene, save = T, title = expression(paste(italic("CLPSL1"), " (T1D)")),
                               labels = c("index"), filter_gene_biotype = c("protein_coding"), border = F, width = 7.5, height = 5.5){
  # Check if the path exists; interactively create the path if not
  if (!dir.exists(dirname(path))) {
    create_dir <- readline(prompt = "Directory does not exist. Do you want to create it? (yes/no): ")
    if (tolower(create_dir) == "yes") { # i.e., input case in-sensitive
      dir.create(dirname(path), recursive = TRUE)
      message(paste("Directory created >>>", dirname(path)))
    } else {
      stop("Directory does not exist and was not created.")
    }
  }
  # Check if the plot already exists to prevent overwriting it because you forget to change the path
  if (file.exists(path)) {
    file.exist.status <- readline(prompt = "Plot already exists! Do you mean to overwrite it or forget to change the path? (yes/no): ")
    if (tolower(file.exist.status) == "yes") { # i.e., input case in-sensitive
      message("Ok, processing the plot...")
    } else {
      stop("Process aborted now.")
    }
  }
  # Save the plot
  if (save) {message(paste("Plot save to >>>", path));pdf(path, width = width, height = height)}
  # plot
  locus_plot(loc, legend_pos = "topright",
             labels = labels,
             filter_gene_biotype = filter_gene_biotype,
             highlight_col = "#E64B35FF",
             use_layout = T,
             border = border,
             recomb_col = "#4DBBD5FF",
             highlight = gene)
  title(main=title)
  if (save) {dev.off()}
}
# conditional analysis ----
#' locate the significant SNP for conditional analysis
#'
#' @param x data.frame of the SNP information
#' @param environment.list tibble of the environment list (see the example for usage)
#' @param significance_level numeric, significance level, default is 5e-8
#'
#' @return message that informs the user of the independant SNP for the following conditional analysis
#' @export
#' @section HLA data analysis:
#'
#' @examples
#' con_dir <- "/Users/leoarrow/project/VKH2024/data/zuo/con_su" # specify the directory to store the HLA original data and subsequent conditional analysis results data
#' files <- list.files(con_dir,full.names = T) %>% as.vector(); files # update it each time
#' x1 <- fread(files[1]) %>% arrange(desc(CHISQ)) # read the data and sort it by CHISQ/P value
#' x2 <- fread(files[2]) %>% arrange(P) # repeat it until no more independent signal can be found.
#' x3 <- fread(files[3]) %>% arrange(P)
#' x4 <- fread(files[4]) %>% arrange(P)
#' x5 <- fread(files[5]) %>% arrange(P)
#' x6 <- fread(files[6]) %>% arrange(P)
#' x7 <- fread(files[7]) %>% arrange(P)
#' x8 <- fread(files[8]) %>% arrange(P)
#'
#' env <- ls() # get the environment; this line if were put in main func will lead to error.
#' environment.list <- tibble(item = as.vector(grep("^x[0-9]+$", x = env, value = TRUE))) # load the environment
#' check_significant_SNP(x8, environment.list, significance_level = 5e-8)
#'
#' # You can mannually check the p-value of one SNP in previous environment.list
#'
check_significant_SNP <- function(x, environment.list, significance_level = 5e-8) {
  if (nrow(environment.list) == 0) {
    message("No matching variables found in the environment.")
    return()
  }
  for (i in 1:nrow(x)) { # i = 1
    con_SNP <- x$SNP[i]
    con_SNP_p <- x$P[i]

    if (con_SNP_p > significance_level) {
      message(paste("SNP: ", con_SNP, " is not significant already."))
      leo_message("The conditional analysis can be over now. So long!")
      break
    }

    message(paste("Locating in previous environment for <<<<<<<", con_SNP, ">>>>>>>"))
    all_pass <- lapply(1:(nrow(environment.list)-1), function(j){
      tmp_ref <- get(environment.list$item[j])
      tmp_ref_p <- tmp_ref %>% filter(SNP == con_SNP) %>% pull(P) %>% as.numeric()
      return(tmp_ref_p < significance_level)
    }) %>% do.call(all, .)

    if (all_pass) {
      message(paste0(" <<<< Passed for SNP: ", con_SNP, " >>>>"))
      leo_message("It can be used for the next SNP for conditional analysis")
      break
    } else {
      leo_message("Not this one! Let's move on to the next one.")
    }

    if (i == nrow(x)) {
      leo_message("The conditional analysis can be over now. So long!")
    }
  }
}

#' # NOT YET
#'
#' #' Convert Visual Acuity Measurements to logMAR
#' #'
#' #' This function converts visual acuity measurements to logMAR values.
#' #' It handles numeric values and special terms such as "CF", "HM", "LP", and "NLP".
#' #'
#' #' @param data A data frame containing visual acuity data.
#' #' @param acuity_cols A character vector of column names in \code{data} to be converted.
#' #'
#' #' @return A data frame with the specified columns converted to numeric logMAR values.
#' #' @export
#' #'
#' #' @examples
#' #' # Assuming clinic_prs is your data frame and 'bcva_od' is the column to convert
#' #' clinic_prs <- convert_to_logMAR(clinic_prs, c('bcva_od', 'bcva_os'))
#' convert_to_logMAR <- function(data, acuity_cols) {
#'   # Define the mapping of special terms to logMAR values
#'   term_map <- c('CF' = 2.0, 'HM' = 2.3, 'LP' = 2.6, 'NLP' = 2.9)
#'
#'   # Perform the conversion using dplyr::mutate and dplyr::across
#'   converted_data <- data %>%
#'     dplyr::mutate(
#'       dplyr::across(
#'         .cols = dplyr::all_of(acuity_cols),
#'         .fns = ~ {
#'           x_upper <- base::toupper(as.character(.x))
#'           # Suppress warnings when converting non-numeric strings to numeric
#'           va_numeric <- suppressWarnings(as.numeric(x_upper))
#'
#'           # Vectorized conditional logic using dplyr::case_when
#'           dplyr::case_when(
#'             # If the value is a special term, map it to the corresponding logMAR value
#'             x_upper %in% names(term_map) ~ as.numeric(term_map[x_upper]),
#'
#'             # If the value is numeric and positive, compute logMAR
#'             grepl("^[0-9.]+$", x_upper) & va_numeric > 0 ~ log10(1 / va_numeric),
#'
#'             # For all other cases (including non-numeric, zero, negative), set to NA
#'             TRUE ~ NA_real_
#'           )
#'         }
#'       )
#'     )
#'
#'   return(converted_data)
#' }
#'
#'
#' #' Convert IOP Measurements by Handling "无" as NA
#' #'
#' #' This function converts intraocular pressure (IOP) measurements by replacing "无" with NA and converting the rest to numeric.
#' #'
#' #' @param data A data frame containing IOP data.
#' #' @param iop_cols A character vector of IOP column names in \code{data} to be converted.
#' #'
#' #' @return A data frame with the specified IOP columns converted to numeric, with "无" as NA.
#' #' @export
#' #'
#' #' @examples
#' #' # Assuming clinic_prs is your data frame and 'iop_od' is the column to convert
#' #' clinic_prs <- convert_iop(clinic_prs, c('iop_od', 'iop_os'))
#' convert_iop <- function(data, iop_cols) {
#'   data <- data %>%
#'     mutate(across(all_of(iop_cols), ~ {
#'       # Replace "无" (case insensitive) with NA
#'       x <- toupper(as.character(.x))
#'       x[x == "无"] <- NA
#'       # Convert to numeric
#'       as.numeric(x)
#'     }))
#'
#'   return(data)
#' }
#'
#'
#' #' Calculate Correlation between Two Vectors
#' #'
#' #' This function calculates the Spearman (default) or Pearson correlation coefficient
#' #' and its associated p-value between two vectors.
#' #' It automatically handles missing values.
#' #'
#' #' @param vector_x A numeric vector.
#' #' @param vector_y A numeric vector of the same length as \code{vector_x}.
#' #' @param method A character string specifying the correlation method ("spearman" or "pearson").
#' #'               Defaults to "spearman".
#' #' @param ... Pass to \code{\link[stats]{cor.test}}.
#' #'
#' #' @return A list with the correlation coefficient and p-value.
#' #' @export
#' #' @seealso \code{\link{correlation_draw}} for plotting correlation results.
#' #' @examples
#' #' vector_x <- c(1, 2, 3, 4, 5)
#' #' vector_y <- c(5, 6, 7, 8, 7)
#' #' result <- correlation_calculate(vector_x, vector_y, method = "pearson")
#' correlation_calculate <- function(vector_x, vector_y, method = "spearman", ...) {
#'   if (!method %in% c("spearman", "pearson")) {
#'     stop("Invalid method. Choose 'spearman' or 'pearson'.")
#'   }
#'
#'   # Remove NA values from both vectors consistently
#'   valid_indices <- complete.cases(vector_x, vector_y)
#'   vector_x <- vector_x[valid_indices]
#'   vector_y <- vector_y[valid_indices]
#'
#'   # Use cor.test to get correlation coefficient and p-value
#'   correlation_test <- cor.test(vector_x, vector_y, method = method, use = "complete.obs", ...)
#'
#'   # Extract correlation coefficient and p-value
#'   result <- data.frame(
#'     correlation_coefficient = as.numeric(correlation_test$estimate),
#'     p_value = correlation_test$p.value
#'   )
#'
#'   return(result)
#' }
#'
#'
#' # 3. 绘制 PRS 与连续变量的散点图及趋势线
#' #' Plot PRS vs Continuous Variables
#' #'
#' #' This function creates scatter plots of PRS against specified continuous variables with linear regression lines.
#' #'
#' #' @param data A data frame containing the PRS and continuous variables.
#' #' @param prs_col The name of the PRS column in \code{data}.
#' #' @param continuous_vars A character vector of continuous variable names.
#' #'
#' #' @return A named list of ggplot objects.
#' #' @export
#' #'
#' #' @examples
#' #' continuous_plots <- plot_prs_vs_continuous(clinic_prs, "prs", continuous_variables)
#' plot_prs_vs_continuous <- function(data, prs_col, continuous_vars) {
#'   plots <- map(continuous_vars, function(var) {
#'     ggplot(data, aes_string(x = var, y = prs_col)) +
#'       geom_point(na.rm = TRUE) +
#'       geom_smooth(method = "lm", na.rm = TRUE) +
#'       labs(title = paste("PRS vs", var))
#'   })
#'   names(plots) <- continuous_vars
#'   return(plots)
#' }
#'
#'
#' # 4. 绘制分类变量中不同类别的 PRS 分布（箱线图）
#' #' Plot PRS Distribution Across Categorical Variables
#' #'
#' #' This function creates box plots showing the distribution of PRS across different categories of specified categorical variables.
#' #'
#' #' @param data A data frame containing the PRS and categorical variables.
#' #' @param prs_col The name of the PRS column in \code{data}.
#' #' @param categorical_vars A character vector of categorical variable names.
#' #'
#' #' @return A named list of ggplot objects.
#' #' @export
#' #'
#' #' @examples
#' #' categorical_plots <- plot_prs_vs_categorical(clinic_prs, "prs", categorical_variables)
#' plot_prs_vs_categorical <- function(data, prs_col, categorical_vars) {
#'   plots <- map(categorical_vars, function(var) {
#'     ggplot(data, aes_string(x = var, y = prs_col)) +
#'       geom_boxplot(na.rm = TRUE) +
#'       labs(title = paste("PRS Distribution across", var))
#'   })
#'   names(plots) <- categorical_vars
#'   return(plots)
#' }
#'
#' # 5. 将 PRS 分组并分析各组中变量的分布
#' #' Analyze Variables Across PRS Groups
#' #'
#' #' This function divides PRS into specified number of groups and analyzes the distribution of other variables within these groups.
#' #'
#' #' @param data A data frame containing the PRS and variables to analyze.
#' #' @param prs_col The name of the PRS column in \code{data}.
#' #' @param vars_to_analyze A character vector of variable names to analyze.
#' #' @param group_num Number of groups to divide the PRS into. Default is 3.
#' #'
#' #' @return A list containing analysis results for each variable.
#' #' @export
#' #'
#' #' @examples
#' #' prs_group_results <- analyze_prs_groups(clinic_prs, "prs", all_variables, group_num = 3)
#' analyze_prs_groups <- function(data, prs_col, vars_to_analyze, group_num = 3) {
#'   data <- data %>%
#'     arrange(prs) %>%
#'     mutate(PRS_group = ntile(.data[[prs_col]], group_num))
#'
#'   results <- list()
#'
#'   for (var in vars_to_analyze) {
#'     var_type <- ifelse(is.numeric(data[[var]]), "continuous", "categorical")
#'
#'     if (var_type == "continuous") {
#'       # Plot variable across PRS groups
#'       plot <- ggplot(data, aes(x = factor(PRS_group), y = .data[[var]])) +
#'         geom_boxplot(na.rm = TRUE) +
#'         labs(title = paste(var, "across PRS groups"), x = "PRS Group")
#'
#'       # Calculate summary statistics
#'       summary_stats <- data %>%
#'         group_by(PRS_group) %>%
#'         summarise(
#'           mean = mean(.data[[var]], na.rm = TRUE),
#'           sd = sd(.data[[var]], na.rm = TRUE),
#'           n = n()
#'         )
#'
#'       results[[var]] <- list(type = "continuous", plot = plot, summary = summary_stats)
#'
#'     } else {
#'       # Plot distribution of categorical variable across PRS groups
#'       plot <- ggplot(data, aes(x = factor(PRS_group), fill = .data[[var]])) +
#'         geom_bar(position = "fill", na.rm = TRUE) +
#'         labs(title = paste(var, "distribution across PRS groups"), x = "PRS Group", y = "Proportion")
#'
#'       # Calculate counts and proportions
#'       counts <- data %>%
#'         group_by(PRS_group, .data[[var]]) %>%
#'         summarise(n = n(), .groups = 'drop') %>%
#'         group_by(PRS_group) %>%
#'         mutate(prop = n / sum(n))
#'
#'       results[[var]] <- list(type = "categorical", plot = plot, counts = counts)
#'     }
#'   }
#'
#'   return(results)
#' }
#'
#' # 6. 综合分析 PRS 与各变量的关系（自动识别变量类型）
#' #' Analyze PRS vs Multiple Variables
#' #'
#' #' This function analyzes the relationship between PRS and multiple variables, automatically identifying variable types and providing appropriate visualizations and statistics.
#' #'
#' #' @param data A data frame containing the PRS and variables to analyze.
#' #' @param prs_col The name of the PRS column in \code{data}.
#' #' @param vars A character vector of variable names to analyze.
#' #'
#' #' @return A list containing analysis results for each variable.
#' #' @export
#' #'
#' #' @examples
#' #' analysis_results <- analyze_prs_vs_variables(clinic_prs, "prs", all_variables)
#' analyze_prs_vs_variables <- function(data, prs_col, vars) {
#'   results <- list()
#'
#'   for (var in vars) {
#'     var_type <- ifelse(is.numeric(data[[var]]), "continuous", "categorical")
#'
#'     if (var_type == "continuous") {
#'       # Calculate correlation
#'       corr <- cor(data[[prs_col]], data[[var]], use = "complete.obs")
#'
#'       # Plot scatter plot
#'       plot <- ggplot(data, aes_string(x = var, y = prs_col)) +
#'         geom_point(na.rm = TRUE) +
#'         geom_smooth(method = "lm", na.rm = TRUE) +
#'         labs(title = paste("PRS vs", var, "- Correlation:", round(corr, 2)))
#'
#'       results[[var]] <- list(type = "continuous", correlation = corr, plot = plot)
#'
#'     } else {
#'       # Plot box plot
#'       plot <- ggplot(data, aes_string(x = var, y = prs_col)) +
#'         geom_boxplot(na.rm = TRUE) +
#'         labs(title = paste("PRS Distribution across", var))
#'
#'       results[[var]] <- list(type = "categorical", plot = plot)
#'     }
#'   }
#'
#'   return(results)
#' }
# This contains need-to-have functions for making BESD files for SMR and HEIDI



#' Filter Chromosomes Based on SNP P-value Threshold
#'
#' This function adds an index column to the input data frame and filters chromosomes based on whether any SNP within the chromosome crosses a specified threshold. If a chromosome has at least one SNP that meets the threshold, all SNPs on that chromosome are retained. Otherwise, all SNPs on that chromosome are removed.
#'
#' @param df A data frame containing SNP data.
#' @param chr_col Character string specifying the name of the chromosome column. Default is `"CHR"`.
#' @param snp_col Character string specifying the name of the SNP identifier column. Default is `"Variant_ID"`.
#' @param p_val_col Character string specifying the name of the p-value column. Default is `"nominal_P_value"`.
#' @param threshold Numeric value specifying the p-value threshold. Default is `5e-8`.
#'
#' @return A filtered data frame with an added `index` column.
#' @export
#' @examples
#' library(dplyr)
#' eqtl_data <- data.frame(
#' CHR = c("1", "1", "2", "2", "3"),
#' Variant_ID = c("rs1", "rs2", "rs3", "rs4", "rs5"),
#' nominal_P_value = c(1e-9, 0.05, 0.2, 1e-7, 0.3)
#' );eqtl_data
#' df_filtered <- filter_chr_basedonSNP_p(
#'   df = eqtl_data,
#'   chr_col = "CHR",
#'   snp_col = "Variant_ID",
#'   p_val_col = "nominal_P_value",
#'   threshold = 5e-8
#' );df_filtered
filter_chr_basedonSNP_p <- function(df,
                               chr_col = "CHR",
                               snp_col = "Variant_ID",
                               p_val_col = "nominal_P_value",
                               threshold = 1.57e-3) {
  chr_sym <- sym(chr_col)
  snp_sym <- sym(snp_col)
  pval_sym <- sym(p_val_col)

  df_filtered <- df %>%
    dplyr::group_by(!!chr_sym) %>%
    dplyr::filter(any((!!pval_sym) < threshold)) %>%
    dplyr::ungroup()
  return(df_filtered)
}

#' Filter Chromosomes Based on SNP P-value Threshold for `.qtltoolsnomi` files
#'
#' This function adds an index column to the input data frame and filters chromosomes based on whether any SNP within the chromosome crosses a specified threshold. If a chromosome has at least one SNP that meets the threshold, all SNPs on that chromosome are retained. Otherwise, all SNPs on that chromosome are removed.
#'
#' @param df A data frame containing SNP data.
#' @param chr_col Character string specifying the name of the chromosome column. Default is `"CHR"`.
#' @param snp_col Character string specifying the name of the SNP identifier column. Default is `"Variant_ID"`.
#' @param gene_col Character string specifying the name of the gene column. Default is `"Gene"`.
#' @param p_val_col Character string specifying the name of the p-value column. Default is `"nominal_P_value"`.
#' @param threshold Numeric value specifying the p-value threshold. Default is `5e-8`.
#'
#' @return A filtered data frame with an added `index` column.
#' @export
#' @examples
#' library(dplyr)
#' eqtl_data <- data.frame(
#' Gene = c("G1", "G1", "G2", "G2", "G3"),
#' CHR = c("1", "1", "2", "2", "3"),
#' Variant_ID = c("rs1", "rs2", "rs3", "rs4", "rs5"),
#' nominal_P_value = c(1e-9, 0.05, 0.2, 1e-7, 0.3)
#' );eqtl_data
#' df_filtered <- filter_chr_basedonSNP_p_qtltools(
#'   df = eqtl_data,
#'   chr_col = "CHR",
#'   snp_col = "Variant_ID",
#'   p_val_col = "nominal_P_value",
#'   threshold = 5e-8
#' );df_filtered
filter_chr_basedonSNP_p_qtltools <- function(df,
                                    chr_col = "CHR",
                                    snp_col = "Variant_ID",
                                    gene_col = "Gene",
                                    p_val_col = "nominal_P_value",
                                    threshold = 1.57e-3) {
  chr_sym <- sym(chr_col)
  snp_sym <- sym(snp_col)
  pval_sym <- sym(p_val_col)
  gene_sym <- sym(gene_col)

  df_filtered <- df %>%
    dplyr::group_by(!!gene_sym, !!chr_sym) %>%
    dplyr::filter(any((!!pval_sym) < threshold)) %>%
    dplyr::ungroup()
  return(df_filtered)
}


# ---- Below is how you aggregate all SMR results for XWAS ----
# smr result should be all stored in a dir in the following format:
# - level 1: qtl type (e.g. mqtl, eqtl, ...)
# - level 2: qtl specific source (e.g. GTEx49, ...)

# 0. Combine SMR res of all CHR from one source ----
#' Combine SMR Results for All Chromosomes
#'
#' This function combines SMR (Summary-data-based Mendelian Randomization) result files across all chromosomes
#' for each unique exposure and outcome pair. The combined results are saved to a specified output directory.
#'
#' @param dir Character. The directory containing SMR result files. Files should follow the naming convention
#'            `exposure_chrX@outcome.smr`, where `X` represents the chromosome number.
#' @param out_dir Character. The output directory where combined SMR files will be saved.
#'                If not specified, defaults to a subdirectory named `chr_combined` within `dir`.
#' @return NULL
#'
#' @examples
#' \dontrun{
#' # Combine SMR results in the "data/smr_results" directory and save to default output directory
#' combine_smr_res_chr(dir = "data/smr_results")
#'
#' # Combine SMR results and specify a custom output directory
#' combine_smr_res_chr(dir = "data/smr_results", out_dir = "data/combined_results")
#' }
#'
#' @importFrom cli cli_alert_info cli_alert_success cli_alert_warning cli_alert_danger
#' @importFrom dplyr filter pull
#' @importFrom data.table fread fwrite
#' @export
combine_smr_res_chr <- function(dir, out_dir="") {
  leo_log("Combine SMR results for all chromosomes.")
  df_tmp <- dplyr::tibble(
    files=list.files(dir, full.names = F, pattern = "smr$"),
    exposures=strsplit(files, "@") %>% sapply(function(x) x[1]) %>% sub("_chr[0-9]+", "", .),
    outcomes=strsplit(files, "@") %>% sapply(function(x) x[2]) %>% sub(".smr", "", .),
    full_paths=list.files(dir, full.names = T, pattern = "smr$")
  )

  if (length(unique(df_tmp$exposures)) > 1) {
    cli::cli_alert_info("Deal with {.emph {length(unique(df_tmp$exposures))}} exposure{?s} seperately.")
  }
  if (length(unique(df_tmp$outcomes)) > 1) {
    cli::cli_alert_info("Deal with {.emph {length(unique(df_tmp$outcomes))}} outcome{?s} seperately.")
  }
  if (out_dir == "") {
    out_dir <- file.path(dir, "chr_combined")
    leo_log("Out dir set to >>>", out_dir, level = "success")
  }
  if (!file.exists(out_dir)) {dir.create(out_dir)}

  for (exposure in unique(df_tmp$exposures)) {
    for (outcome in unique(df_tmp$outcomes)) {
      files_paths <- df_tmp %>% dplyr::filter(exposures == exposure, outcomes == outcome) %>% pull("full_paths")
      res <- lapply(files_paths, data.table::fread)
      res <- do.call(rbind, res)
      out_file <- paste0(out_dir, "/chr_combine_", exposure, "@", outcome, ".smr")
      cli::cli_alert_info("Write to file: {.path {out_file}}")
      data.table::fwrite(res, out_file, sep = "\t")
    }
  }
  leo_log("ALL DONE!", level = "success")
  return(NULL)
}

# 1. FDR/Bonferroni ----
#' Adjust SMR Results with FDR and Bonferroni Corrections
#'
#' It applies FDR/Bonferroni corrections for a single SMR result.
#' The corrected results are saved in an `fdr` subdirectory within the output directory.
#'
#' @param smr_result_path Character. The path containing SMR result file. Files should have the `.smr` extension.
#' @param out_dir Character. The output directory where adjusted files will be saved.
#'                If not specified, defaults to create a dir named `fdr` within dir-name (smr_result_path).
#' @param writePath Character. The path to write the adjusted results.
#' ----
#' @param add_info_cols Logical. Whether to add information columns for: QTL_type, Source, Tissue and Outcome. Default is `TRUE`.
#' @param QTL_type Character. The type of the QTL for SMR analysis.
#' @param Source Character. The name of the Source.
#' @param Tissue Character. The name of the Tissue.
#' @param Outcome_name Character. The name of the Outcome.
#' ----
#' @param hla Logical. Whether to pre-exclude the HLA region probes. Default is `False`.
#' @param write_out Logical. Whether to write the adjusted results to a file. Default is `TRUE`.
#'
#' @return NULL
#' @examples
#' \dontrun{
#' leo_smr_adjust("~/project/iridocyclitis/output/smr-t2d/sqtl/GTEx49/chr_combined/chr_combine_sQTL_Adipose_Subcutaneous@iri3.smr",
#'                writePath = "", out_dir = "~/project/iridocyclitis/output/smr-t2d/sqtl/GTEx49")
#' leo_smr_adjust("~/project/iridocyclitis/output/smr-t2d/sqtl/GTEx49/chr_combined/chr_combine_sQTL_Adipose_Subcutaneous@iri3.smr",
#'                writePath = "./haha.fdr", out_dir = "")
#' }
#' @importFrom cli cli_alert_info
#' @importFrom vroom vroom vroom_write
#' @importFrom dplyr mutate %>% filter
#' @importFrom stringr str_replace
#' @export
leo_smr_adjust <- function(smr_result_path, writePath = "", out_dir = "",
                           QTL_type = "", Source = "", Tissue = "", Outcome_name = "", add_info_cols = T,
                           hla = F, write_out = T) {
  smr_result <- vroom::vroom(smr_result_path, show_col_types = F)
  if (hla) {
    smr_result <- smr_result %>%
      dplyr::mutate(HLA_Probe = ifelse((ProbeChr == 6 & Probe_bp >= 25000000 & Probe_bp <= 34000000), "Yes", "No")) %>%
      dplyr::filter(HLA_Probe == "No")
    nrow_HLA_probe <- smr_result %>% filter(HLA_Probe == "Yes") %>% nrow()
    cli::cli_alert_info(" - Filtering out {.emph {nrow_HLA_probe}} probe{?s} for {basename(smr_result_path)}") # seems unnecessary
  }
  smr_result <- smr_result %>%
    mutate(Pass_HEIDI = ifelse(p_HEIDI >= 0.05, "Pass", "Fail"),
           N_probe = nrow(.),
           FDR = p.adjust(p_SMR, method = "BH", n = N_probe[1]),
           Pass_FDR = ifelse(FDR < 0.05, "Pass", "Fail"),
           Bonferroni = p.adjust(p_SMR, method = "bonferroni", n = N_probe[1]),
           Pass_Bonferroni = ifelse(Bonferroni < 0.05, "Pass", "Fail"))

  if (add_info_cols) {
    # check if required columns are provided
    if (QTL_type == "" | Source == "" | Tissue == "" | Outcome_name == "") {
      cli::cli_alert_danger("[QTL_type], [Source], [Tissue] and [Outcome_name] are all required.")
      return(invisible(NULL))
    }
    smr_result <- smr_result %>%
      dplyr::mutate(
        QTL_type = QTL_type,
        Source = Source,
        Tissue = Tissue,
        Outcome = Outcome_name
      ) %>%
      dplyr::select(QTL_type, Source, Tissue, Outcome, everything())
  }

  if (write_out) {
    basename <- basename(smr_result_path) %>% gsub(".smr", ".fdr", .)
    dirname <- dirname(smr_result_path)

    if (writePath == "") {
      if (out_dir == "") {
        cli::cli_alert_warning("No writePath & out_dir set")
        out_dir <- file.path(dirname, "fdr")
      }
      if (!file.exists(out_dir)) {dir.create(out_dir)}
      writePath <- file.path(out_dir, basename)
    } else {
      writePath <- writePath # this will overide the basename setting
    }

    cli::cli_alert_success(" - Writing to >>> {.path {writePath}}")
    vroom::vroom_write(smr_result, writePath, delim = "\t")
    return(invisible(NULL))
  } else {
    return(smr_result)
  }
}


#' Batch Adjust SMR Results with FDR and Bonferroni Corrections
#'
#' This function applies FDR/Bonferroni corrections to all SMR results within a specified directory.
#'
#' @param dir Character. The directory containing SMR result files. Files should have the `.smr` extension and follow the naming convention `exposure@outcome.smr`.
#' @param out_dir Character. The output directory where the adjusted SMR files will be saved.
#'                If not specified, defaults to creating a `fdr` directory within the input directory.
#' @param pattern Character. A regular expression pattern to match SMR result files. Default is `"\.smr$"` (i.e., files ending with `.smr`).
#' @param ... Additional arguments to be passed to `leo_smr_adjust`.
#'
#' @return NULL.
#' @examples
#' \dontrun{
#' leo_smr_adjust_loop(dir     = "~/project/iridocyclitis/output/smr/sqtl/GTEx49/chr_combined",
#'                     out_dir = "~/project/iridocyclitis/output/smr/sqtl/GTEx49/fdr")
#' }
#' @importFrom cli cli_alert_info cli_alert_success cli_alert_warning
#' @importFrom dplyr filter pull
#' @importFrom stringr str_split
#' @export
leo_smr_adjust_loop <- function(dir, out_dir="", pattern = "\\.smr$", QTL_type, Source, ...) {
  leo_log("Adjusting SMR results for all files in the", leo_message(dir, color = 36, return = T), "directory.")
  if (out_dir == "") {
    dirname <- dirname(dir)
    out_dir <- file.path(dirname, "fdr")
    if (!file.exists(out_dir)) dir.create(out_dir, recursive = TRUE)
    cli::cli_alert_warning("out_dir set to {.path {out_dir}} as there are no pre-set out_dir.")
  } else {
    if (!file.exists(out_dir)) dir.create(out_dir, recursive = TRUE)
    out_dir = out_dir
  }

  # list all smr file
  smr_files <- list.files(path = dir, pattern = pattern, full.names = TRUE) # Get list of .smr files in the folder
  if (length(smr_files) == 0) {
    leo_log("No `.smr` files found in the directory.", level = "danger")
    return(invisible(NULL))
  }
  for (smr_file in smr_files) { # Loop through each .smr file and apply leo_smr_adjust function
    cli::cli_alert_info(" - Processing: {smr_file}")
    basename <- basename(smr_file) %>% sub(".smr", "", .)
    Tissue = stringr::str_split(basename, "@", simplify = T)[1]
    Outcome_name = stringr::str_split(basename, "@", simplify = T)[2]
    cli::cli_alert_info(" - Tissue: {.val {Tissue}}, Source: {.val {Outcome_name}}")
    leo_smr_adjust(smr_file, out_dir = out_dir,
                   QTL_type = QTL_type, Source = Source, Tissue = Tissue, Outcome_name = Outcome_name,
                   ...)
  }
  leo_log("ALL DONE!", level = "success")
  return(invisible(NULL))
}

# 2. Combine all results for each outcomes ----
#' Combine `.fdr` files for one or multiple outcomes (seperately)
#'
#' @param dir       Character. The parent folder that contains subfolders with fdr files.
#' @param outcome   Character or character vector. One or more outcomes to search in file names.
#' @param out_dir   Character. Output folder; default is to create "combine_1outcome" under \code{dir}.
#' @return          NULL. This function writes combined files to disk directly.
#' @examples
#' \dontrun{
#' combine_smr_res_1outcome("/Users/leoarrow/project/iridocyclitis/output/smr", "iri3")
#' }
#' @importFrom cli cli_alert_danger cli_alert_success cli_alert_warning cli_alert_info
#' @importFrom dplyr bind_rows select everything
#' @importFrom data.table fwrite
#' @importFrom vroom vroom
#' @export
combine_smr_res_1outcome <- function(dir, outcome, out_dir = file.path(dir, "combine_1outcome")) {
  date_str <- format(Sys.Date(), "%Y%m%d"); cli::cat_rule(paste0("[",date_str,"] Combining SMR results"), col = "blue")
  fdr_files <- list.files(path = dir, pattern = "\\.fdr$", recursive = TRUE, full.names = TRUE)
  if (length(fdr_files) == 0) stop("No `.fdr` files found in the given directory")

  # Loop each self-defined outcome
  for (oc in outcome) {
    leo_log("Processing outcome >>>", leo_message(oc, color = 36, return = T))
    # Select files with this outcome
    sub_files <- fdr_files[grepl(oc, basename(fdr_files))]
    if (length(sub_files) == 0) {
      leo_log(" - No `.fdr` file matched for the outcome >>>", leo_message(oc, color = 36, return = T), level = "warning")
      next
    }

    # Read and combine
    merged_df_list <- lapply(sub_files, function(fp) vroom::vroom(fp, show_col_types = F, progress = F))
    merged_df <- do.call(rbind, merged_df_list)

    # Output file
    if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE) # Create out_dir if not exist
    out_file <- file.path(out_dir, paste0("smr_res_", date_str, "@", oc, ".all"))
    cli::cli_alert_success("Writing => {out_file}")
    data.table::fwrite(merged_df, file = out_file, sep = "\t")
  }
  leo_log("All Done!", level = "success")
  return(invisible(NULL))
}

# 3. Extract significant results from `.all` files ----
#' Extract significant results from `.all` files
#'
#' This function scans the `combine_1outcome` folder for `.all` files,
#' filters rows where \code{Pass_FDR == "Pass"} or \code{Pass_Bonferroni == "Pass"}
#' (depending on \code{pass_type} argument), and writes the significant subset
#' to a new file (e.g., `smr_res_YYYYMMDD_iri3.sig.all`).
#'
#' @param dir        Character. The main `combine_1outcome` folder from \func{combine_smr_res_1outcome}.
#' @param pass_type  Character. Which significance criterion to use:
#'                   one of \code{c("FDR", "Bonferroni", "both")}.
#'                   - "FDR": keep rows where \code{Pass_FDR == "Pass"}
#'                   - "Bonferroni": keep rows where \code{Pass_Bonferroni == "Pass"}
#'                   - "both": keep rows where either FDR or Bonferroni is "Pass"
#' @param out_dir    Character. Where to write significant results.
#'                   Default \code{dir/combine_1outcome/sig}.
#'
#' @return NULL. Writes `.sig.all` files to disk.
#'
#' @examples
#' \dontrun{
#' # For the directory "/Users/leoarrow/project/iridocyclitis/output/smr-t2d",
#' # after running combine_smr_res_1outcome, we have .all files in
#' # "smr-t2d/combine_1outcome".
#'
#' leo_smr_extract_sig_res(
#'   dir       = "/Users/leoarrow/project/iridocyclitis/output/smr-t2d",
#'   pass_type = "FDR"
#' )
#' }
#' @importFrom cli cli_alert_success cli_alert_info cli_alert_warning
#' @importFrom vroom vroom vroom_write
#' @importFrom dplyr filter
#' @export
leo_smr_extract_sig_res <- function(dir, pass_type = c("FDR", "Bonferroni"), out_dir   = "") {
  cli::cat_rule("Extract significant results from `.all` files", col = "blue")
  pass_type <- match.arg(pass_type)
  all_files <- list.files(path = dir, pattern = "\\.all$", full.names = TRUE) # List all .all files, e.g. "smr_res_20241230_iri3.all"
  for (all_file in all_files) {
    fn <- basename(all_file);cli::cli_alert_info("Processing file: {fn}")
    df <- vroom::vroom(all_file, show_col_types = FALSE, progress = FALSE) %>%
      dplyr::filter(Pass_HEIDI == "Pass")
    df_sig <- switch(
      pass_type,
      "FDR" = dplyr::filter(df, .data$Pass_FDR == "Pass"),
      "Bonferroni" = dplyr::filter(df, .data$Pass_Bonferroni == "Pass")
    )

    if (nrow(df_sig) == 0) {
      cli::cli_alert_warning("No significant rows found in {fn} under '{pass_type}'. Skipped.")
      next
    }

    # Output: Build & write output filename: e.g. "smr_res_20241230_iri3.sig.all"
    if (out_dir == "") {
      out_dir <- file.path(dir, "sig") # Default out_dir => dir/combine_1outcome/sig
      cli::cli_alert_info("No out_dir specified. So out_dir set to {.path {out_dir}}")
    }
    if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)
    out_fn <- sub("\\.all$", ".sig.all", fn)
    out_fpath <- file.path(out_dir, out_fn)
    vroom::vroom_write(df_sig, out_fpath, delim = "\t")
    cli::cli_alert_success("Wrote significant results => {out_fpath} with {nrow(df_sig)} rows.")
  }
  return(invisible(NULL))
}

# 4. Gimme Shared ones for 2 XWAS outcomes ----
# In this section, we locate the shared XWAS results for 2 outcomes
#' Merge multiple SMR files and keep only shared probes for 2 outcomes
#'
#' This function finds intersected \code{probeID} across all provided files
#' and merges them into a single data frame using \code{inner_join}.
#'
#' @param dir        Character. A directory containing SMR files (e.g. ".sig.all" files).
#'                   If provided, the function will read all matching files in this directory.
#' @param file_paths Character vector. A set of absolute paths to SMR files. (Priority over \code{dir})
#'                   If this is non-NULL, \code{dir} is ignored.
#' @param pattern    Character. Regex pattern for searching files in \code{dir}. Default is "\\.sig\\.all$".
#' @param out_file   Character. If not empty, write the merged result to this path. Otherwise only return in R.
#'
#' @return A tibble containing shared probes across all specified files. If \code{out_file} is provided, the result is written to disk and the function returns \code{NULL}.
#'
#' @examples
#' \dontrun{
#' # 1) Merge all .sig.all files in a directory:
#' merged_df <- leo_smr_merge_shared_probes(
#'   dir = "/path/to/smr-t2d/combine_1outcome/sig"
#' )
#'
#' # 2) Merge specific files by absolute paths:
#' files_vec <- c(
#'   "/path/to/smr/combine_1outcome/smr_res_20241230_iri3.all",
#'   "/path/to/smr/combine_1outcome/smr_res_20241230_t1d1.all"
#' )
#' merged_df <- leo_smr_merge_shared_probes(
#'   file_paths = files_vec,
#'   out_file = "shared_probes_merged.tsv"
#' )
#' }
#' @importFrom vroom vroom vroom_write
#' @importFrom dplyr inner_join select
#' @importFrom purrr reduce
#' @importFrom stringr str_remove str_split_fixed
#' @importFrom cli cli_alert_info cli_alert_success cli_alert_danger cat_rule
#' @export
leo_smr_merge_shared_probes <- function(
    dir         = NULL,
    file_paths  = NULL,
    pattern     = "\\.sig\\.all$",
    out_file    = "") {
  cli::cat_rule("Merge multiple SMR files and keep only shared probes", col = "blue")

  # 1) Identify files
  if (!is.null(file_paths)) {
    # If file_paths is provided, ignore dir
    leo_log("Reading files from 'file_paths': ", file_paths)
    smr_files <- file_paths
  } else {
    # Otherwise, search dir for pattern
    if (is.null(dir) || !dir.exists(dir)) stop("Please provide a valid 'dir' or a non-empty 'file_paths'.")
    cli::cli_alert_info("Reading {.emph {length(list.files(dir))}} file{?s} in {.path {dir}}")
    smr_files <- list.files(
      path       = dir,
      pattern    = pattern,
      full.names = TRUE
    )
  }
  if (length(smr_files) != 2) stop("Only 2 files are permitted here to find shared probes.")

  # 2) Read all files
  df_list <- lapply(smr_files, function(fp) {
    dat <- vroom::vroom(fp, show_col_types = FALSE, progress = FALSE)
  })

  # 3) Merge with c("QTL_type", "Source", "Tissue", "probeID", "ProbeChr", "Probe_bp", "Gene")
  merged_df <- dplyr::inner_join(
    df_list[[1]], df_list[[2]],
    by = c("QTL_type", "Source", "Tissue", "probeID", "ProbeChr", "Probe_bp", "Gene"),
    suffix = c(paste0(".", unique(df_list[[1]][["Outcome"]])),
               paste0(".", unique(df_list[[2]][["Outcome"]])))
  ) %>% select("QTL_type", "Source", "Tissue", "probeID", "ProbeChr", "Probe_bp", "Gene", everything())

  # 4) Optionally write to out_file
  if (out_file != "") {
    vroom::vroom_write(merged_df, out_file, delim = "\t")
    cli::cli_alert_success("Merged data written to {out_file} with {nrow(merged_df)} rows.")
  } else {
    cli::cli_alert_info("Merged data has {nrow(merged_df)} shared rows across all files.")
  }
  return(merged_df)
}
# F1
#' Perform LD Clumping Locally or via Reference Panel
#'
#' This function performs LD clumping using either a local PLINK binary file (\code{bfile})
#' or a 1000 Genomes super population panel. Requires the \code{ieugwasr} and \code{plinkbinr} packages.
#'
#' @param dat Dataframe containing GWAS summary statistics. Must contain columns:
#' \code{SNP}, \code{pval.exposure}, and \code{id.exposure}.
#' @param pop Super-population code when using online LD reference panel.
#' Options: "AFR", "AMR", "EAS", "EUR", "SAS". Required if \code{bfile = NULL}.
#' @param bfile Path to PLINK binary reference panel for local clumping.
#' If provided, \code{pop} will be ignored.
#' @param plink_bin Path to PLINK binary executable. Default tries to auto-detect.
#' @param clump_kb Clumping window in kilobases. Default = 10000.
#' @param clump_r2 Clumping r² threshold. Default = 0.001.
#' @keywords tsmr:
#' @return A subset of the input dataframe containing independent SNPs.
#' @importFrom ieugwasr ld_clump
#' @importFrom dplyr tibble filter
#' @export
#' @note
#' Reference:
#' https://github.com/MRCIEU/TwoSampleMR/issues/173
#' https://blog.csdn.net/xiaozheng1213/article/details/126269969
#' library(ieugwasr)
#' library(plinkbinr) # devtools::install_github("explodecomputer/plinkbinr")
#' plinkbinr::get_plink_exe()
clump_data_local <- function(dat, pop = NULL, bfile = NULL, plink_bin = NULL) {
 require(ieugwasr); require(plinkbinr)
 leo_log(" - Clumping data locally")
 leo_message(paste0(" - Reminder: bfile located: ", "/Users/leoarrow/project/ref/1kg.v3/EUR"))
 if (is.null(pop) & is.null(bfile)) { stop("Must indicate LD method") }
 if (!is.null(pop) & is.null(bfile)) { leo_message("Performing LD online") }
 if (is.null(pop) & !is.null(bfile)) { leo_message("Performing LD locally") }
 # if (!is.null(pop) & !is.null(bfile)) { stop("Only one LD method can be used") }
 dat1 <- ieugwasr::ld_clump(
  dat = dplyr::tibble(rsid=dat$SNP, pval=dat$pval.exposure, id=dat$id.exposure),
  clump_kb = 10000,
  clump_r2 = 0.001,
  pop = pop,
  bfile = bfile,
  plink_bin = plinkbinr::get_plink_exe()
 )
 dat2<- subset(dat, SNP %in% dat1$rsid)
 return(dat2)
}

# F2
#' Extract instruments locally for MR Analysis
#'
#' Filters SNPs by p-value threshold and performs LD clumping with flexible column mapping.
#'
#' @param dat Dataframe containing GWAS summary statistics
#' @param p P-value cutoff (default = 5e-8)
#' @param pop Super-population code for LD reference (default = "EUR")
#' @param phenotype_col Column name for phenotype (default = "Phenotype")
#' @param snp_col Column name for SNP IDs (default = "SNP")
#' @param chr_col Column name for chromosome (default = "CHR")
#' @param pos_col Column name for position (default = "POS")
#' @param effect_allele_col Column name for effect allele (default = "A1")
#' @param other_allele_col Column name for non-effect allele (default = "A2")
#' @param beta_col Column name for effect size (default = "BETA")
#' @param se_col Column name for standard error (default = "SE")
#' @param pval_col Column name for p-values (default = "P")
#' @param eaf_col Column name for effect allele frequency (default = "EAF")
#' @param N Column name for sample size (default = "Neff", set NULL to exclude)
#' @param bfile Path to PLINK binary reference panel (default = NULL)
#' @param plink_bin Path to PLINK executable (default = NULL)
#'
#' @return Formatted exposure data ready for MR analysis
#' @export
#' @importFrom TwoSampleMR format_data
#' @examples
#' \dontrun{
#' # Custom column names example
#' extract_instruments_local(
#'   dat = gwas_data,
#'   phenotype_col = "Trait",
#'   snp_col = "rsID",
#'   chr_col = "Chromosome",
#'   pos_col = "Position"
#' )
#' }
extract_instruments_local <- function(dat, p = 5e-08, pop = "EUR",
                                      phenotype_col = "Phenotype",
                                      snp_col = "SNP",
                                      chr_col = "CHR",
                                      pos_col = "POS",
                                      effect_allele_col = "A1",
                                      other_allele_col = "A2",
                                      beta_col = "BETA",
                                      se_col = "SE",
                                      pval_col = "P",
                                      eaf_col = "EAF",
                                      N = "Neff",
                                      bfile = NULL,
                                      plink_bin = NULL) {
  # check cols ---------------------------------------------------------------
  required_cols <- c(snp_col, chr_col, pos_col, effect_allele_col,
                     other_allele_col, beta_col, se_col, pval_col, phenotype_col)
  missing_cols <- setdiff(required_cols, names(dat))
  if (length(missing_cols) > 0) {
    leo_log("Missing required columns: ", paste(missing_cols, collapse = ", "))
    stop()
  }

  if (!is.null(N) && !N %in% names(dat)) {
    stop("Sample size column '", N, "' not found in dataset")
  }

  # filter based on P ---------------------------------------------------------------
  leo_log(" - Filtering SNPs by {p} as P-value threshold")
  instruments <- dat[dat[[pval_col]] < p, ]
  if (nrow(instruments) == 0) {
    message("No SNPs passed the P-value threshold (p < ", p, ")")
    return(NULL)
  }
  leo_message(paste0(" - <", nrow(instruments), "> SNP passed the P-value threshold"))

  # build args --------------------------------------------------------
  format_args <- list(
    dat = instruments,
    type = "exposure",
    phenotype_col = phenotype_col,
    snp_col = snp_col,
    chr_col = chr_col,
    pos_col = pos_col,
    effect_allele_col = effect_allele_col,
    other_allele_col = other_allele_col,
    beta_col = beta_col,
    se_col = se_col,
    pval_col = pval_col,
    min_pval = 1e-200
  )
  # optional
  if (!is.null(eaf_col) && eaf_col %in% names(dat)) {
    format_args$eaf_col <- eaf_col
  } else {
    message("Note: EAF column not found, harmonization may be affected")
  }

  if (!is.null(N)) {
    format_args$samplesize_col <- N
    message("Using sample size column: ", N)
  }

 leo_message(" - Using effective N as default!!!")
 instruments <- TwoSampleMR::format_data(
  instruments,
  type = "exposure",
  phenotype_col = phenotype_col,
  snp_col = "SNP",
  chr_col = "CHR",
  pos_col = "POS",
  effect_allele_col = "A1",
  other_allele_col = "A2",
  eaf_col = "EAF",
  beta_col = "BETA",
  se_col = "SE",
  pval_col = "P",
  samplesize_col = N,
  min_pval = 1e-200
 )
 instruments <- clump_data_local(instruments, pop = pop, bfile = bfile) # F2中执行了F1（本地Clump）
 return(instruments)
}

# F3
#' format outcome data
#'
#' @param dat a dataframe for outcome with SNP, CHR, POS, A1, A2, EAF, BETA, SE, P, Phenotype, samplesize columns
#' @param snp a str vector out of iv$SNP
#' @param N N column name for sample size (effective or observed)
#' @keywords tsmr:
#' @return a tsmr format outcome dataframe
format_outcome <- function(dat, snp = iv$SNP, N = "Neff") {
 leo_message("You should check samplesize column (effective or observed)")
 leo_message(paste0("Now using <", N, "> for samplesize indice !!!!!!!!"))
 out <- format_data(
  dat,
  snps = snp,
  type = "outcome",
  # defaut col names
  phenotype_col = "Phenotype",
  snp_col = "SNP",
  chr_col = "CHR",
  pos_col = "POS",
  effect_allele_col = "A1",
  other_allele_col = "A2",
  eaf_col = "EAF",
  beta_col = "BETA",
  se_col = "SE",
  pval_col = "P",
  samplesize_col = N,
  min_pval = 1e-200
 )
 return(out)
}

# F4
#' find_proxy
#'
#' @description
#' `find_proxy` finds the proxy snp for the miss iv
#'
#' @param miss_iv iv datafram in tsmr exposure format, which can not locate snp in the outcome
#' @param miss_snp snp in the miss_iv; can be inferred using miss_iv$SNP
#' @param outcome_snp a str vector containing all snp in the outcome; this NOT the entire outcome gwas summary statistics
#' @param pop reference panel from 1kg (LDlinkR param)
#' @param gb genome build (LDlinkR param)
#' @param proxy_output_path a full path to save the proxy file when using ldlink
#' @param proxy_file pre-calculated proxy file path (full); do provide this if the proxy file is already generated !!!
#' @param token token of `LDlinkR`
#' @keywords tsmr:
#' @return a updated missiv with `proxy.snp` `proxy.effect.allele` `proxy.other.allele` `r2` col
#' @examples
#' # This function can be used when many iv can not locate corresponding snp in the outcome in tsmr analysis
#' @examples
#' miss_iv <- iv[!iv$SNP %in% dat_h$SNP,] # iv is estracted iv via tsmr package;dat_h is a standard output of harmonise_data()
#' miss_snp <- miss_iv$SNP
#' outcome_snp <- iri_nc$SNP
#' proxy_output_path <- "Full path to where you wanna store the LDlinkR output"
#'  proxy_iv <- find_proxy(miss_iv, miss_snp, outcome_snp,
#'              proxy_file = "/Users/leoarrow/project/iridocyclitis/output/tsmr//combined_query_snp_list_grch38.txt",
#'              proxy_output_path = NULL)
#'  # bak
#'  proxy_iv$target.snp <- proxy_iv$SNP # target snp
#'  proxy_iv$target.A1 <- proxy_iv$effect_allele.exposure
#'  proxy_iv$target.A2 <- proxy_iv$other_allele.exposure
#'  # replace for tsmr
#'  proxy_iv$SNP <- proxy_iv$proxy.snp
#'  proxy_iv$effect_allele.exposure <- proxy_iv$proxy.A1
#'  proxy_iv$other_allele.exposure <- proxy_iv$proxy.A2
#'  iv_f <- bind_rows(non_miss_iv, proxy_iv) # f for final
#'  dat_h_proxy <- harmonise_data(iv_f, out_nc_proxy)
#'  mr(dat_h_proxy) # nailed it!
find_proxy <- function(miss_iv, miss_snp, outcome_snp, proxy_file=NULL, proxy_output_path=NULL, pop="EUR", gb="grch38", token="") {
 require(LDlinkR); require(tidyverse); require(data.table)
 # sub-part 1: using ldlink to find proxy ---------
 # this part can be skipped if the file can be provided in advance.
 if (is.null(proxy_file)) {
  # if you did not pre-calculate the proxy file, then calculate it here
  if(is.null(proxy_output_path)) {stop("Need to input where LDlink should generate the proxy file.")}
  wd <- getwd() # record work path
  setwd(proxy_output_path)
  message(paste0("Save the proxy file into path >>> ", proxy_output_path))
  message(paste0(" --- using parameter: ", pop, " (ref population)"))
  message(paste0(" --- using parameter: ", gb, " (genome_build)"))
  message(paste0("##### LDlinkR could take a while if there is many miss snps #####"))
  p <- LDlinkR::LDproxy_batch(miss_snp, # LDproxy_batch needs to write results in one txt file
                              pop = pop,  # pop = c("CEU", "TSI", "FIN", "GBR", "IBS"),
                              r2d = "r2",
                              token = token,
                              append = T, # one txt file (T) or plural txt files for each snp (F)
                              genome_build = gd)
  setwd(wd) # back to the work path
  proxy <- fread(file.path(proxy_output_path, paste0("combined_query_snp_list_", gb, ".txt"))) %>%
   filter(R2 > 0.6) %>%
   # Here, `query_A1` corresponds to `proxy_A1`; `query_A2` to `proxy_A2`
   tidyr::separate(Correlated_Alleles, sep = "[,=]", remove = FALSE, into = c("query_A1", "proxy_A1", "query_A2", "proxy_A2")) %>%
   select(query_snp, RS_Number, R2,query_A1, proxy_A1, query_A2, proxy_A2) %>%
   mutate(SNP_in_outcome = RS_Number %in% outcome_snp) %>%
   filter(SNP_in_outcome == T)
  message(paste0(" - A total of <",dim(proxy)[1], "> potential proxy snp"))
  message(paste0(" - A total of <",length(unique(proxy$query_snp)), "> miss_iv have proxy snp"))
 } else {
  proxy <- fread(proxy_file) %>% # e.g., fread("/Users/leoarrow/project/iridocyclitis/output/tsmr//combined_query_snp_list_grch38.txt")
   filter(R2 > 0.6) %>%
   tidyr::separate(Correlated_Alleles, sep = "[,=]", remove = FALSE, into = c("query_A1", "proxy_A1", "query_A2", "proxy_A2")) %>%
   select(query_snp, RS_Number, R2,query_A1, proxy_A1, query_A2, proxy_A2) %>%
   mutate(SNP_in_outcome = RS_Number %in% outcome_snp) %>%
   filter(SNP_in_outcome == T)
  message(paste0(" - A total of <",dim(proxy)[1], "> potential proxy snp"))
  message(paste0(" - A total of <",length(unique(proxy$query_snp)), "> miss_iv have proxy snp"))
 }

 # sub-part 2: match proxy ---------
 for (snp in miss_iv$SNP) { # for loop for snp in miss_iv$SNP
  message(paste(" - Locating proxy for: ", snp))
  miss_iv_line <- miss_iv[miss_iv$SNP == snp, ]
  miss_iv_A1 <- miss_iv_line$effect_allele.exposure
  miss_iv_A2 <- miss_iv_line$other_allele.exposure
  tmp_proxy <- proxy[proxy$query_snp == snp,] %>% dplyr::arrange(-R2, .by_group = T)
  if (nrow(tmp_proxy) == 0) {message(paste(" - Could not find proxy for: ", snp)); next}
  # For potential proxy snps
  match <- F
  i <- 1 # i for index
  while (!match)
  { # while loop for proxy snp
   # snp check
   proxy_snp_line <- tmp_proxy[i,]
   query_snp <- proxy_snp_line$query_snp
   proxy_snp <- proxy_snp_line$RS_Number
   if (query_snp == proxy_snp) {i <- i+1; next} # just in case
   # allele check
   query_A1 <- proxy_snp_line$query_A1
   query_A2 <- proxy_snp_line$query_A2
   proxy_A1 <- proxy_snp_line$proxy_A1
   proxy_A2 <- proxy_snp_line$proxy_A2
   logi_allele_match1 <- (miss_iv_A1 == query_A1 & miss_iv_A2 == query_A2) # condition 1
   logi_allele_match2 <- (miss_iv_A1 == query_A2 & miss_iv_A2 == query_A1) # condition 2
   if (logi_allele_match1 || logi_allele_match2) {
    miss_iv$proxy.snp[miss_iv$SNP == snp] <- proxy_snp
    miss_iv$proxy.r2[miss_iv$SNP == snp] <- proxy_snp_line$R2
    # if matched
    if (logi_allele_match1) {
     miss_iv$proxy.A1[miss_iv$SNP == snp] <- proxy_A1
     miss_iv$proxy.A2[miss_iv$SNP == snp] <- proxy_A2
    } else {
     miss_iv$proxy.A1[miss_iv$SNP == snp] <- proxy_A2
     miss_iv$proxy.A2[miss_iv$SNP == snp] <- proxy_A1
    }
    match <- T
    # if not matched
   } else {
    i <- i+1
    if (i > nrow(tmp_proxy)) {
     message(paste(" - Could not find proxy for: ", snp))
     break
    }
   }
  # proxy while loop end here
  }
  if (!match) {message(paste(" - No suitable proxy found for: ", snp))}
 # snp for loop end here
 }
 message(" ######## Done #########")
 miss_iv_with_proxy <- miss_iv %>% filter(!is.na(proxy.snp))
 located_proxy_length <- length(miss_iv_with_proxy$proxy.snp)
 miss_iv_length <- length(miss_iv$SNP)
 message(paste0(" - A total of <", located_proxy_length, "> proxy located."))
 message(paste0(" - A total of <", miss_iv_length-located_proxy_length, "> proxy not located."))
 return(miss_iv_with_proxy)
}

# F5
#' perform_mr_for_one_pair
#'
#' `perform_mr_for_one_pair` perform a MR for one pair of exp and out
#'
#' @param dat_h harmonized data
#' @param exp a str indicating the exposure in dat_h
#' @param out a str indicating the outcome in dat_h
#' @param res_dir dir path where the result fo MR analysis stored
#' @param fig_dir dir path where the figure of MR analysis stored
#' @param save_plot only save the plot if T, defaut T.
#'
#' @keywords tsmr:
#' @export
#' @return list(res_pair=res_pair, res_pair_presso=res_pair_presso)
#' @examples
#' clusterEvalQ(cl, {
#' library(vroom)
#' library(tidyverse)
#' library(TwoSampleMR)
#' library(ggplot2)
#' library(ggsci)
#' source("./code/1.0.tsmr_packages.R")
#' })
#' clusterExport(cl, varlist = c("uni_pair","dat_h"))
mr_one_pair <- function(dat_h, exp = "", out = "", save_plot = T, res_dir= "./output/tsmr", fig_dir="./figure/tsmr") {
  # Initialize
  pairname <- paste0(exp, " VS ", out); leo_message(paste0(" - MR Pair: ", pairname))
  if (!dir.exists(res_dir)) {dir.create(res_dir, recursive = T)}; leo_message(paste0(" - Setting Check: `res_dir` using ", res_dir))
  if (!dir.exists(fig_dir)) {dir.create(fig_dir, recursive = T)}; leo_message(paste0(" - Setting Check: `fig_dir` using ", fig_dir))

  # MR for one specific pair of exposure and outcome
  dat_h_pair <- dat_h %>% filter(exposure == exp, outcome == out)
  dat_h_pair <- subset(dat_h_pair, mr_keep); rownames(dat_h_pair) <- NULL
  if (nrow(dat_h_pair) < 2) {
    res_pair <- mr(dat_h_pair, method_list =  c("mr_wald_ratio"))
  } else {
    res_pair <- mr(dat_h_pair, method_list =  c("mr_ivw", "mr_egger_regression", "mr_weighted_median"))
  }
  res_pair <- generate_odds_ratios(res_pair)
  res_pair <- res_pair %>%
    mutate(R2_total = scales::percent(sum(dat_h_pair$R2), accuracy = 0.01),
           Neff_max_exp = as.integer(max(dat_h_pair$samplesize.exposure[1])),
           Neff_max_out = as.integer(max(dat_h_pair$samplesize.outcome[1])))

  # mr_heterogeneity & pleiotropy test
  heterogeneity_pair <- mr_heterogeneity(dat_h_pair)
  pleiotropy_res <- mr_pleiotropy_test(dat_h_pair)
  presso_res <- tryCatch(expr = {run_mr_presso(dat_h_pair, SignifThreshold = 0.05, NbDistribution = ifelse(nrow(dat_h_pair)/0.05<1000, 1000, nrow(dat_h_pair)/0.05))},
                         error = function(e) {message("Error in MR-PRESSO: ", e$message);return(NULL)})

  # integrate results into `res_pair`
  res_pair$heterogeneity_IVW_Q <- ifelse(!is.null(heterogeneity_pair$Q[which(heterogeneity_pair$method == "Inverse variance weighted")]), heterogeneity_pair$Q[which(heterogeneity_pair$method == "Inverse variance weighted")], "NA")
  res_pair$heterogeneity_IVW_Q_df <- ifelse(!is.null(heterogeneity_pair$Q_df[which(heterogeneity_pair$method == "Inverse variance weighted")]), heterogeneity_pair$Q_df[which(heterogeneity_pair$method == "Inverse variance weighted")], "NA")
  res_pair$heterogeneity_IVW_Q_pval <- ifelse(!is.null(heterogeneity_pair$Q_pval[which(heterogeneity_pair$method == "Inverse variance weighted")]), heterogeneity_pair$Q_pval[which(heterogeneity_pair$method == "Inverse variance weighted")], "NA")
  res_pair$heterogeneity_Egger_Q <- ifelse(!is.null(heterogeneity_pair$Q[which(heterogeneity_pair$method == "MR Egger")]), heterogeneity_pair$Q[which(heterogeneity_pair$method == "MR Egger")], "NA")
  res_pair$heterogeneity_Egger_Q_df <- ifelse(!is.null(heterogeneity_pair$Q_df[which(heterogeneity_pair$method == "MR Egger")]), heterogeneity_pair$Q_df[which(heterogeneity_pair$method == "MR Egger")], "NA")
  res_pair$heterogeneity_Egger_Q_pval <- ifelse(!is.null(heterogeneity_pair$Q_pval[which(heterogeneity_pair$method == "MR Egger")]), heterogeneity_pair$Q_pval[which(heterogeneity_pair$method == "MR Egger")], "NA")
  res_pair$pleiotropy_Egger_intercept <- ifelse(!is.null(pleiotropy_res$egger_intercept), pleiotropy_res$egger_intercept, "NA")
  res_pair$pleiotropy_Egger_intercept_se <- ifelse(!is.null(pleiotropy_res$se), pleiotropy_res$se, "NA")
  res_pair$pleiotropy_Egger_intercept_pval <- ifelse(!is.null(pleiotropy_res$pval), pleiotropy_res$pval, "NA")

  # presso results
  if (!is.null(presso_res)) {
    res_pair_presso <- presso_res[[1]]$`Main MR results` %>% mutate(Exposure = exp, Outcome = out) %>% select(Exposure, Outcome, everything())
    outlier_detected <- ifelse(is.na(res_pair_presso$`Causal Estimate`[2]), "NO", "YES")
    if (outlier_detected == "YES") {
      res_pair_presso$outlier_detected <- outlier_detected
      res_pair_presso$Global_RSSobs <- presso_res[[1]]$`MR-PRESSO results`$`Global Test`$RSSobs
      res_pair_presso$Global_Pvalue <- presso_res[[1]]$`MR-PRESSO results`$`Global Test`$Pvalue
      res_pair_presso$Distortion_Coefficient <- presso_res[[1]]$`MR-PRESSO results`$`Distortion Test`$`Distortion Coefficient`
      res_pair_presso$Distortion_Pvalue <- presso_res[[1]]$`MR-PRESSO results`$`Distortion Test`$Pvalue
    } else {
      res_pair_presso$outlier_detected <- c(outlier_detected, "NA")
      res_pair_presso$Global_RSSobs <- c(presso_res[[1]]$`MR-PRESSO results`$`Global Test`$RSSobs, NA)
      res_pair_presso$Global_Pvalue <- c(presso_res[[1]]$`MR-PRESSO results`$`Global Test`$Pvalue, NA)
      res_pair_presso$Distortion_Coefficient <- NA
      res_pair_presso$Distortion_Pvalue <- NA
    }
  } else {
    res_pair_presso <- NULL
  }

  # res_path <- file.path(res_dir, paste0("tsmr_", exp, "_VS_", out, ".tsv")); leo_message(paste0(" >>> Save result to: ", res_path))
  # vroom::vroom_write(res_pair, res_path)
  # res_path <- file.path(res_dir, paste0("tsmr_presso_", exp, "_VS_", out, ".tsv")); leo_message(paste0(" >>> Save result to: ", res_path))
  # vroom::vroom_write(res_pair_presso, res_path)

  if (save_plot) {
    #' >>>>>>>>>>>>>  draw and save draw   >>>>>>>>>>>>>
    #' p1: Scatter plot
    #' p2: Forest plot
    #' p3: Funnel plot
    #' p4: LOO plot
    #' For Forest: width = 7, height = 8 (T1D)
    #' For Forest: width = 7, height = 10 (T2D)
    #' For others: width = 7, height = 6
    #' fig_dir <- "./figure/tsmr"
    # >>>>>>>>>>>>> Scatter Plot >>>>>>>>>>>>>>>>>>>
    # p1 <- mr_scatter_plot_modified(mr_results = res_pair, dat = dat_h_pair); p1[[1]]
    p1 <- mr_scatter_plot(mr_results = res_pair, dat = dat_h_pair)
    p1[[1]] <- p1[[1]]+ggsci::scale_color_npg()+ggsci::scale_fill_npg()+ggplot2::theme_classic()+
      ggplot2::theme(legend.position = "top",legend.direction = "vertical",
                     axis.title.x = element_text(size = 16, colour = "black"),  # X label
                     axis.title.y = element_text(size = 16, colour = "black"),  # Y label
                     axis.text = element_text(size = 14, colour = "black"), # x/y axis size
                     legend.title = element_text(size = 14, face = "italic"), # legend title
                     legend.text = element_text(size = 12),
                     legend.background = element_blank()
      )+ggplot2::guides(colour = ggplot2::guide_legend(ncol = 3))
    p1[[1]][["layers"]][[1]][["aes_params"]]$colour <- "black" # error bar (|)
    p1[[1]][["layers"]][[1]][["aes_params"]]$alpha <- 0.75 # error bar (|)
    p1[[1]][["layers"]][[2]][["aes_params"]]$colour <- "black" # error bar (-)
    p1[[1]][["layers"]][[2]][["aes_params"]]$alpha <- 0.75 # error bar (-)
    p1[[1]][["layers"]][[3]][["aes_params"]]$colour <- "black" # snp point
    p1[[1]][["layers"]][[4]][["aes_params"]]$size <- 1 # geom_abline line
    p1[[1]][["layers"]][[4]][["aes_params"]]$alpha <- 0.75 # geom_abline line
    fig_path <- file.path(fig_dir, paste0("tsmr_scatter_", exp, "_VS_", out, ".pdf")); leo_message(paste0(" >>> Save figure to: ", fig_path))
    ggsave(fig_path, plot = p1[[1]], width = 7, height = 6)
    # >>>>>>>>>>>>> mr_forest_plot / mr_funnel_plot >>>>>>>>>>>>>>>>>>>
    res_single_pair <- mr_singlesnp(dat_h_pair)
    p2 <- mr_forest_plot(res_single_pair)
    p3 <- mr_funnel_plot(res_single_pair)
    p2[[1]] <- p2[[1]]+ggsci::scale_color_npg()+ggsci::scale_fill_npg()+ggplot2::theme_classic()+
      ggplot2::theme(legend.position = "none",
                     axis.title.y = element_text(colour = "black"),
                     axis.title.x = element_text(colour = "black"),
                     axis.text = element_text(colour = "black"))
    p3[[1]] <- p3[[1]]+ggsci::scale_color_npg()+ggsci::scale_fill_npg()+ggplot2::theme_classic()+
      ggplot2::theme(legend.title = element_text(size = 14, face = "italic"),
                     legend.text = element_text(size = 12),
                     legend.position = "top",legend.direction = "horizontal",
                     axis.title.y = element_text(size = 16,colour = "black"),
                     axis.title.x = element_text(size = 16,colour = "black"),
                     axis.text = element_text(size = 14,colour = "black"))
    fig_path <- file.path(fig_dir, paste0("tsmr_forrest_", exp, "_VS_", out, ".pdf")); leo_message(paste0(" >>> Save figure to: ", fig_path))
    if (grepl("T2D*", exp)) {
      ggsave(fig_path, plot = p2[[1]], width = 7, height = 14)
    } else {
      ggsave(fig_path, plot = p2[[1]], width = 7, height = 8)}
    fig_path <- file.path(fig_dir, paste0("tsmr_funnel_", exp, "_VS_", out, ".pdf")); leo_message(paste0(" >>> Save figure to: ", fig_path))
    ggsave(fig_path, plot = p3[[1]], width = 7, height = 6)
    # >>>>>>>>>>>>> LOO Plot >>>>>>>>>>>>>>>>>>>
    loo_pair = mr_leaveoneout(dat_h_pair)
    p4 <- mr_leaveoneout_plot(loo_pair)
    p4[[1]] <- p4[[1]]+ggsci::scale_color_npg()+ggsci::scale_fill_npg()+ggplot2::theme_classic()+
      ggplot2::theme(legend.position = "none",
                     axis.title.y = element_text(colour = "black"),
                     axis.title.x = element_text(colour = "black"),
                     axis.text = element_text(colour = "black"))
    fig_path <- file.path(fig_dir, paste0("tsmr_loo_", exp, "_VS_", out, ".pdf")); leo_message(paste0(" >>> Save figure to: ", fig_path))
    if (grepl("T2D*", exp)) {
      ggsave(fig_path, plot = p4[[1]], width = 7, height = 14)
    } else {
      ggsave(fig_path, plot = p4[[1]], width = 7, height = 8)}
  }

  # reture `res-pair` and `presso` results as a list
  return(list(
    res_pair=res_pair %>% select(-id.exposure,-id.outcome) %>% select(exposure, outcome, everything()),
    res_pair_presso=res_pair_presso
    ))
}


#' Modified MR Scatter Plot
#'
#' The `mr_scatter_plot` in the `TwoSampleMR` package could be better.
#' This is a modified version of `mr_scatter_plot` in the `TwoSampleMR` package
#' When the slope of two method is really close, the scatter plot may not properly plot them!
#' Change the line type here mannually herein then.
#'
#' @param mr_results same as TwoSampleMR::mr_scatter_plot
#' @param dat same as TwoSampleMR::mr_scatter_plot
#'
#' @keywords tsmr:
#' @export
#'
#' @examples
#' p1 <- mr_scatter_plot_modified(mr_results = res_pair, dat = dat_h_pair)
#' print(p1[[1]])
mr_scatter_plot_modified <- function(mr_results, dat) {
  #' library(ggplot2);library(ggsci);library(TwoSampleMR);library(dplyr)
  mrres <- plyr::dlply(dat, c("id.exposure", "id.outcome"), function(d) {
    d <- plyr::mutate(d)
    if (nrow(d) < 2 | sum(d$mr_keep) == 0) {
      return(blank_plot("Insufficient number of SNPs"))
    }
    d <- subset(d, mr_keep)
    index <- d$beta.exposure < 0
    d$beta.exposure[index] <- d$beta.exposure[index] * -1
    d$beta.outcome[index] <- d$beta.outcome[index] * -1
    mrres <- subset(mr_results, id.exposure == d$id.exposure[1] &
                      id.outcome == d$id.outcome[1])
    mrres$a <- 0
    if ("MR Egger" %in% mrres$method) {
      temp <- mr_egger_regression(d$beta.exposure, d$beta.outcome,
                                  d$se.exposure, d$se.outcome, default_parameters())
      mrres$a[mrres$method == "MR Egger"] <- temp$b_i
    }
    if ("MR Egger (bootstrap)" %in% mrres$method) {
      temp <- mr_egger_regression_bootstrap(d$beta.exposure, d$beta.outcome,
                                            d$se.exposure, d$se.outcome, default_parameters())
      mrres$a[mrres$method == "MR Egger (bootstrap)"] <- temp$b_i
    }

    # debugging
    # print(mrres)

    p <- ggplot2::ggplot(data = d, ggplot2::aes(x = beta.exposure, y = beta.outcome)) +
      ggplot2::geom_errorbar(ggplot2::aes(ymin = beta.outcome - se.outcome, ymax = beta.outcome + se.outcome),
                             colour = "black", alpha= 0.75, width = 0) +
      ggplot2::geom_errorbarh(ggplot2::aes(xmin = beta.exposure - se.exposure, xmax = beta.exposure + se.exposure),
                              colour = "black", alpha= 0.75, height = 0) +
      ggplot2::geom_point(alpha= 0.75) +
      ggplot2::geom_abline(data = mrres, ggplot2::aes(intercept = a, slope = b, colour = method, linetype = method),
                           show.legend = TRUE, size = 1.5, alpha = 0.8) +
      # ggplot2::scale_colour_manual(values = c("Inverse variance weighted" = "red",
      #                                         "MR Egger" = "blue",
      #                                         "Weighted median" = "green",
      #                                         "IVW radial" = "purple")) +
      ggplot2::scale_linetype_manual(values = c("Inverse variance weighted" = "solid", # change setting here!!!!!
                                                "MR Egger" = "solid",
                                                "Weighted median" = "solid",
                                                "IVW radial" = "dotted")) +
      ggsci::scale_color_npg()+ggsci::scale_fill_npg()+ggplot2::theme_classic()+
      ggplot2::labs(colour = "MR Test", linetype = "MR Test", x = paste("SNP effect on", d$exposure[1]),
                    y = paste("SNP effect on", d$outcome[1])) +
      ggplot2::theme(legend.position = "top", legend.direction = "vertical") +
      ggplot2::theme(legend.position = "top",legend.direction = "vertical",
                     axis.title.x = element_text(size = 16, colour = "black"),  # X label
                     axis.title.y = element_text(size = 16, colour = "black"),  # Y label
                     axis.text = element_text(size = 14, colour = "black"), # x/y axis size
                     legend.title = element_text(size = 14, face = "italic"), # legend title
                     legend.text = element_text(size = 12),
                     legend.background = element_blank()
      )+ggplot2::guides(colour = ggplot2::guide_legend(ncol = 4), linetype = ggplot2::guide_legend(ncol = 4))
    return(p)
  })
  mrres
}

#' mrlap_one_pair
#'
#' `mrlap_one_pair` perform the MR-lap for one pair of exposure and outcome
#' [MR-lap](https://github.com/n-mounier/MRlap?tab=readme-ov-file)
#'
#' @param exposure_name exposure_name
#' @param outcome_name outcome_name
#' @param exposure_data exposure_data
#' @param outcome_data outcome_data
#' @param ld_path ldsc required file
#' @param hm3_path ldsc required file; tutorial use nomhc version list
#' @param log logi, if T, would save ldsc log to log_path, defaut F
#' @param log_path path to where you wanna store the ldsc log
#'
#' @keywords tsmr:
#' @export
mrlap_one_pair <- function(exposure_data, outcome_data, exposure_name, outcome_name, ld_path, hm3_path, log = F, log_path = ".") {
  leo_message(paste0(" - MR-lap for: ", exposure_name, " VS ", outcome_name))
  if (log) {leo_message(paste0("log file would be stored at >>>"), log_path)}
  # locate iv_mrlap snps
  iv_mrlap <- extract_instruments_local(exposure_data, p = 5e-08, N = "Neff", bfile = "/Users/leoarrow/project/ref/1kg.v3/EUR", plink_bin = plinkbinr::get_plink_exe())
  iv_mrlap <- iv_mrlap %>%
    mutate(R2 = (2*(beta.exposure)^2*(eaf.exposure*(1-eaf.exposure)))/((se.exposure^2) * samplesize.exposure),
           F = R2*(samplesize.exposure-2)/(1-R2)) %>%
    filter(F > 10) %>%
    mutate(maf.exposure = ifelse(eaf.exposure<0.5, eaf.exposure, 1-eaf.exposure)) %>%
    filter(maf.exposure > 0.01)
  iv_mrlap$id.exposure <- iv_mrlap$exposure
  out_mrlap <- format_outcome(outcome_data, iv_mrlap$SNP)
  out_mrlap <- out_mrlap %>%
    mutate(maf.outcome = ifelse(eaf.outcome<0.5, eaf.outcome, 1-eaf.outcome)) %>%
    subset(maf.outcome>0.01) %>%
    mutate(id.outcome = outcome)
  dat_h_mrlap <- harmonise_data(iv_mrlap, out_mrlap) %>% subset(mr_keep)

  # merge exposure and outcome with w_hm3.xxx.snplist (with/without MHC)
  hm3_snp.list <- fread(hm3_path) %>% select(SNP)
  iv_snp.list <- dat_h_mrlap %>% select(SNP)
  snp.list <- rbind(hm3_snp.list, iv_snp.list) %>% unique()
  exposure_data <- exposure_data %>% filter(SNP %in% snp.list$SNP) %>% select(-Neff)
  outcome_data <- outcome_data %>% filter(SNP %in% snp.list$SNP) %>% select(-Neff)

  # MR-lap
  wd <- getwd()
  if (log) {setwd(log_path)}
  A <- MRlap(exposure = exposure_data,
             exposure_name = exposure_name,
             outcome = outcome_data,
             outcome_name = outcome_name,
             ld = ld_path,
             hm3 = hm3_path,
             save_logfiles = log,
             do_pruning = FALSE,
             user_SNPsToKeep = dat_h_mrlap$SNP
             )
  setwd(wd)

  # Results
  res_lap_pair <- data.frame(
    exposure = exposure_name,
    outcome = outcome_name,
    m_IVs = A[[1]]$m_IVs,
    observed_effect = A[[1]]$observed_effect,
    observed_se = A[[1]]$observed_effect_se,
    observed_p = A[[1]]$observed_effect_p,
    corrected_effect = A[[1]]$corrected_effect,
    corrected_effect_se = A[[1]]$corrected_effect_se,
    corrected_effect_p = A[[1]]$corrected_effect_p,
    test_difference = A[[1]]$test_difference,
    p_difference = A[[1]]$p_difference
  )
  return(res_lap_pair)
}


.onLoad <- function(libname, pkgname) {
  leo_message(" 🦁🦁🦁 Welcome to use the LEO package ! 🦁🦁🦁", color = "33")
  current_time <- format(Sys.time(), "%Y-%m-%d %H:%M:%S")
  leo_message(paste0(" 🦁🦁🦁 System Time: ", current_time, " 🦁🦁🦁"), color = "33")



  ns <- asNamespace(pkgname)
  # 获取包中所有对象的名称
  objs <- ls(ns, all.names = TRUE)

  # 对每个函数进行字节码编译，并清除 srcref 属性
  for(n in objs) {
    obj <- get(n, envir = ns)
    if (is.function(obj)) {
      compiled_obj <- compiler::cmpfun(obj)
      attr(compiled_obj, "srcref") <- NULL
      assign(n, compiled_obj, envir = ns)
    }
  }
}
